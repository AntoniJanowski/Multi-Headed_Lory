{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "main_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(main_dir)\n",
    "\n",
    "import model_classes\n",
    "from model_classes import *\n",
    "# from MH_Lori_poprawianie import *\n",
    "from MH_Lori import *\n",
    "from dataloader import *\n",
    "import dataloader\n",
    "from helper_functions import *\n",
    "import torch\n",
    "from transformers import PretrainedConfig\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import copy\n",
    "import lightning.pytorch as pl\n",
    "# from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a non-vectorised version of Lori (by Miriam Lipniacka)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: [batch_size, seq_len, hidden_size] - input embeddings\n",
    "# Output: [batch_size, seq_len, num_experts] - expert routing weights\n",
    "class Router_miriam(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.num_experts_per_token = config.num_experts_per_token\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.num_experts = config.num_experts\n",
    "\n",
    "        self.expert_embeddings = nn.Parameter(torch.randn(self.num_experts, self.hidden_size)).to(config.device)\n",
    "        torch.nn.init.kaiming_uniform_(self.expert_embeddings, nonlinearity='linear')\n",
    "\n",
    "    def forward(self, x):\n",
    "        dot = torch.einsum(\"bsh,eh->bse\", x, self.expert_embeddings)\n",
    "        # top_k_out = torch.topk(dot, k=self.num_experts_per_token)\n",
    "        # top_k = (float(\"-inf\") * torch.ones_like(dot)).scatter_(dim=-1, index=top_k_out.indices, src=top_k_out.values)\n",
    "        # res = torch.nn.functional.softmax(top_k, dim=-1)\n",
    "        res = torch.nn.functional.softmax(dot, dim=-1)\n",
    "        return res\n",
    "    \n",
    "import math\n",
    "\n",
    "# Input: [batch_size, seq_len, hidden_size] - input embeddings\n",
    "# Output: [batch_size, seq_len, hidden_size] - output embeddings\n",
    "class MoE_Lory(nn.Module):\n",
    "    \"\"\"version which takes first not random tokens up to expert_capacity\"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.num_experts = config.num_experts\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.num_experts_per_token = config.num_experts_per_token\n",
    "        self.capacity_factor = config.capacity_factor\n",
    "        self.T_segments=config.T_segments\n",
    "        # You can change experts representation if you want\n",
    "        # self.experts = nn.ModuleList([MLP(config) for _ in range(self.num_experts)])\n",
    "        #not as above but as below instead so as to compare more easily with the vectorized version\n",
    "        self.intermediate_size = config.intermediate_size\n",
    "        self.first_linear = nn.Parameter(torch.randn(self.num_experts, self.intermediate_size, self.hidden_size))\n",
    "        torch.nn.init.kaiming_uniform_(self.first_linear, nonlinearity='linear')\n",
    "        self.second_linear = nn.Parameter(torch.randn(self.num_experts, self.hidden_size, self.intermediate_size))\n",
    "        torch.nn.init.kaiming_uniform_(self.second_linear, nonlinearity='linear')\n",
    "\n",
    "        self.router = Router_miriam(config)\n",
    "\n",
    "    def compute_out(self, data,linear1,linear2):\n",
    "        return linear2 @ torch.nn.functional.relu(linear1 @ data)\n",
    "\n",
    "    def merge_expert(self, weights):\n",
    "        num_exp,_,_=weights.shape\n",
    "        # expanded_weights1 = torch.ones((num_exp, self.intermediate_size, self.hidden_size)) * weights\n",
    "        # expanded_weights2 = torch.ones((num_exp, self.hidden_size, self.intermediate_size)) * weights\n",
    "        # linear1 = expanded_weights1 @ self.first_linear\n",
    "        # linear2 = expanded_weights1 @ self.second_linear\n",
    "        weighted_first_linear = torch.sum(weights * self.first_linear, dim=0)\n",
    "        weighted_second_linear = torch.sum(weights * self.second_linear, dim=0)\n",
    "        return weighted_first_linear,weighted_second_linear\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, hidden_size = x.shape\n",
    "        #assert hidden_size == self.hidden_size\n",
    "        # expert_capacity = math.ceil(batch_size * seq_len / self.num_experts * self.capacity_factor)\n",
    "        result = torch.zeros_like(x)\n",
    "        segment_size=seq_len//self.T_segments\n",
    "        for i in range(batch_size):\n",
    "            for t in range(self.T_segments):\n",
    "                segment=x[i, t*segment_size:(t+1)*segment_size]\n",
    "                #print(\"segment shape check:\",segment.shape,\"seq_len/T, hidden_dim\")\n",
    "\n",
    "                if t==0:\n",
    "                  with torch.no_grad():\n",
    "                    h_x=segment.sum(axis=0)/segment_size\n",
    "                    h_start = h_x.unsqueeze(dim  = 0)\n",
    "                    h_x=h_x.unsqueeze(0)\n",
    "                    h_x=h_x.unsqueeze(0)\n",
    "                    #print(\"h_x shapecheck:\",h_x.shape)\n",
    "                    # print(f'h_x shape: {h_x.shape}, input routera')\n",
    "                    old_weights = self.router(h_x)\n",
    "                    # print(f'output routera: {old_weights.shape} old weights')\n",
    "                    log_w = old_weights\n",
    "                    # print(old_weights.shape)\n",
    "                    old_weights=old_weights.permute(2,0,1)\n",
    "                    #print(\"old_weights shapecheck:\",old_weights.shape)\n",
    "                    merged_linear1,merged_linear2=self.merge_expert(old_weights)\n",
    "                    merged_linear1_log = merged_linear1\n",
    "                    merged_linear2_log = merged_linear2\n",
    "                  for j in range(segment_size):\n",
    "                    result[i, t*segment_size+j] = self.compute_out(x[i, t*segment_size+j],merged_linear1,merged_linear2)\n",
    "                else:\n",
    "                  h_x=segment.sum(axis=0)/segment_size\n",
    "                  \n",
    "                  h_x=h_x.unsqueeze(0)\n",
    "                  h_start = torch.cat((h_start, h_x), dim = 0)\n",
    "\n",
    "                  h_x=h_x.unsqueeze(0)\n",
    "                  weights=self.router(h_x)\n",
    "                  log_w = torch.cat((log_w, weights), dim = 1)\n",
    "                  weights=weights.permute(2,0,1)\n",
    "                  #print(\"weights shapecheck:\",weights.shape)\n",
    "                  merged_linear1,merged_linear2=self.merge_expert(old_weights)\n",
    "                  old_weights=weights\n",
    "                  for j in range(segment_size):\n",
    "                    result[i, t*segment_size+j] = self.compute_out(x[i, t*segment_size+j],merged_linear1,merged_linear2)\n",
    "\n",
    "        return result, h_start, log_w, merged_linear1_log, merged_linear2_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_config = dict(\n",
    "    vocab_size=5000,\n",
    "    max_position_embeddings=None,#256\n",
    "    num_attention_heads=8,\n",
    "    num_hidden_layers=None,\n",
    "    hidden_dropout_prob=0.1,\n",
    "    hidden_size=128,\n",
    "    intermediate_size=512,\n",
    "    num_labels=2,#2 co to robi?\n",
    "    device = DEVICE #I added this one\n",
    ")\n",
    "moe_config = PretrainedConfig(\n",
    "    **base_config,\n",
    "    T_segments=5,\n",
    "    num_experts=2,\n",
    "    capacity_factor=None, #2.0\n",
    "    num_experts_per_token=None,#1\n",
    "    ff_cls=MoE_Lory\n",
    ")\n",
    "\n",
    "config_small= PretrainedConfig(\n",
    "    num_experts_per_token=2,\n",
    "    hidden_size=128,\n",
    "    num_attention_heads = 8,\n",
    "    num_MH_MOE_heads = 1,\n",
    "    num_experts=2,\n",
    "    batch_size = 5,\n",
    "    seq_len = 20,\n",
    "    capacity_factor = 3,\n",
    "    device = device,\n",
    "    intermediate_size = 512,\n",
    "    forward_layer_class = MH_Lori,\n",
    "    vocab_size = 5000,\n",
    "    n_layers = 8,\n",
    "    no_lori_segments = 5,\n",
    "    py_lightning_loging = False,\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(),\n",
    "    lr = 0.0006, #SET TO 0.0002\n",
    "    betas = (0.9, 0.95),\n",
    "    treat_mh_lori_as_regular_lori = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 20, 128])\n"
     ]
    }
   ],
   "source": [
    "lory = MoE_Lory(moe_config).to(DEVICE)\n",
    "lory.eval()\n",
    "batch_size, seq_len, hidden_size=5,20,128\n",
    "\n",
    "input = torch.randn((batch_size, seq_len, hidden_size)).to(DEVICE) * 10\n",
    "v, h_start, w_m, mlm1, mlm2 = lory(input)\n",
    "print(v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 20, 128])\n",
      "False 4.284083843231201e-08\n"
     ]
    }
   ],
   "source": [
    "mh_lori = MH_Lori(config_small).to(config_small.device)\n",
    "mh_lori.router.expert_embeddings.data = torch.transpose(lory.router.expert_embeddings.data, 0, 1)\n",
    "mh_lori.first_linear.data = lory.first_linear.data\n",
    "mh_lori.second_linear.data = lory.second_linear.data\n",
    "\n",
    "mh_lori.eval()\n",
    "o = mh_lori(input)\n",
    "# o, h_antoni, w_a, mla1, mla2 = mh_lori(input)\n",
    "print(o.shape)\n",
    "\n",
    "print(torch.equal(o, v), torch.max(abs(o - v)).detach().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAXIMUM DIFRENCE BETWEEN OUTPUTS::::::::::::::::::::   7.450580596923828e-08\n",
      "MAXIMUM DIFRENCE BETWEEN OUTPUTS::::::::::::::::::::   5.960464477539063e-08\n",
      "MAXIMUM DIFRENCE BETWEEN OUTPUTS::::::::::::::::::::   1.0058283805847168e-07\n",
      "MAXIMUM DIFRENCE BETWEEN OUTPUTS::::::::::::::::::::   1.043081283569336e-07\n",
      "MAXIMUM DIFRENCE BETWEEN OUTPUTS::::::::::::::::::::   6.705522537231445e-08\n",
      "MAXIMUM DIFRENCE BETWEEN OUTPUTS::::::::::::::::::::   5.960464477539063e-08\n",
      "MAXIMUM DIFRENCE BETWEEN OUTPUTS::::::::::::::::::::   4.470348358154297e-08\n",
      "MAXIMUM DIFRENCE BETWEEN OUTPUTS::::::::::::::::::::   6.705522537231445e-08\n",
      "MAXIMUM DIFRENCE BETWEEN OUTPUTS::::::::::::::::::::   7.450580596923828e-08\n",
      "MAXIMUM DIFRENCE BETWEEN OUTPUTS::::::::::::::::::::   5.029141902923584e-08\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    input = torch.randn((batch_size, seq_len, hidden_size)).to(DEVICE) * 10\n",
    "    v, h_start, w_m, mlm1, mlm2 = lory(input)\n",
    "    mh_lori = MH_Lori(config_small).to(config_small.device)\n",
    "    mh_lori.router.expert_embeddings.data = torch.transpose(lory.router.expert_embeddings.data, 0, 1)\n",
    "    mh_lori.first_linear.data = lory.first_linear.data\n",
    "    mh_lori.second_linear.data = lory.second_linear.data\n",
    "\n",
    "    mh_lori.eval()\n",
    "    o = mh_lori(input)\n",
    "    # o, h_antoni, w_a, mla1, mla2 = mh_lori(input)\n",
    "\n",
    "    print('MAXIMUM DIFRENCE BETWEEN OUTPUTS::::::::::::::::::::  ',torch.max(abs(o - v)).detach().item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
