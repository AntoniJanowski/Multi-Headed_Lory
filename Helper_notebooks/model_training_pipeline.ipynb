{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "main_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(main_dir)\n",
    "\n",
    "import model_classes\n",
    "from model_classes import *\n",
    "from MH_Lori import *\n",
    "from MH_MoE import *\n",
    "from dataloader import *\n",
    "import dataloader\n",
    "from helper_functions import *\n",
    "import torch\n",
    "from transformers import PretrainedConfig\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import copy\n",
    "#import lightning.pytorch as pl\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import pandas as pd\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_small= PretrainedConfig(\n",
    "    num_experts_per_token=4,\n",
    "    hidden_size=256,\n",
    "    num_attention_heads = 4,\n",
    "    num_MH_MOE_heads = 4,\n",
    "    num_experts=8,\n",
    "    batch_size = 20,\n",
    "    seq_len = 512,\n",
    "    capacity_factor = 3,\n",
    "    device = device,\n",
    "    intermediate_size = 512,\n",
    "    forward_layer_class = VectorizedMoE,\n",
    "    vocab_size = 30522,\n",
    "    n_layers = 12,\n",
    "    no_lori_segments = 32,\n",
    "    py_lightning_loging = False,\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(),\n",
    "    lr = 0.001, #SET TO 0.0002\n",
    "    betas = (0.9, 0.98),\n",
    "    treat_mh_lori_as_regular_lori = True,\n",
    "    load_balancing_coefficient=0.01,\n",
    "    proportions = [0.97, 0.01, 0.01, 0.01] # null, train, validation, test\n",
    ")\n",
    "\n",
    "config = config_small\n",
    "\n",
    "#training hiperparams\n",
    "save_every_n_baches = 500 #how often do you wish to save the model\n",
    "epochs = 10\n",
    "\n",
    "#path to folders where you want to save model checkpoints and val and train logs\n",
    "model_saving_path = 'D:/Projekt_NLP/Saved_stuff/saved_models'\n",
    "log_saving_path = 'D:/Projekt_NLP/Saved_stuff/logs/vectorized_moe'\n",
    "\n",
    "model_name='Normal_moe_model' #name of the model in saving logs\n",
    "saving_filename = 'Vectorised_MOE_175M-{epoch}-{step}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1201 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 513])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of usage:\n",
    "l = give_dataloaders(batch_size = config.batch_size, seq_len = config.seq_len + 1, proportions = config.proportions)\n",
    "train_dataloader = l[\"train_dataloader\"]\n",
    "val_dataloader = l[\"val_dataloader\"]\n",
    "test_dataloader = l[\"test_dataloader\"]\n",
    "sample = next(iter(train_dataloader))\n",
    "# print(sample)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Model Size: 167.79 MB, total number of parameters: 175,938,792\n",
      "Estimated Model Size: 108.06 MB, total number of parameters: 113,307,648\n",
      "Estimated Model Size: 8.00 MB, total number of parameters: 8,388,608\n",
      "Total GPU memory: 12.8843776 GB\n",
      "Reserved GPU memory: 10.036969472 GB\n",
      "Allocated GPU memory: 0.744733184 GB\n",
      "Free GPU memory: 9.292236288 GB\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(config_small).to(config_small.device)\n",
    "estimate_model_size(model)\n",
    "estimate_model_size(model.layers)\n",
    "estimate_model_size(model.layers[0].forward_layer)\n",
    "get_gpu_memory()\n",
    "print(isinstance(model, LightningModule))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute this to make shure all parameters are registerd properly\n",
    "\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Parameter name: {name}, Parameter shape: {param.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type             | Params\n",
      "------------------------------------------------\n",
      "0 | loss_fn    | CrossEntropyLoss | 0     \n",
      "1 | embedding  | Embedding        | 7.8 M \n",
      "2 | layers     | ModuleList       | 28.3 M\n",
      "3 | final_proj | Linear           | 7.8 M \n",
      "------------------------------------------------\n",
      "44.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "44.0 M    Total params\n",
      "175.939   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Komputer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]   VALIDATION: Batch 0, loss 10.512404441833496\n",
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  1.82it/s]   VALIDATION: Batch 1, loss 10.517236709594727\n",
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Komputer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 0/? [00:00<?, ?it/s]    TRRAINING: Batch 0, loss 10.528090476989746\n",
      "Epoch 0: |          | 1/? [00:01<00:00,  0.98it/s, v_num=26]   TRRAINING: Batch 1, loss 10.408585548400879\n",
      "Epoch 0: |          | 2/? [00:01<00:00,  1.12it/s, v_num=26]   TRRAINING: Batch 2, loss 9.805338859558105\n",
      "Epoch 0: |          | 3/? [00:02<00:00,  1.16it/s, v_num=26]   TRRAINING: Batch 3, loss 9.181699752807617\n",
      "Epoch 0: |          | 4/? [00:03<00:00,  1.19it/s, v_num=26]   TRRAINING: Batch 4, loss 10.045382499694824\n",
      "Epoch 0: |          | 5/? [00:04<00:00,  1.21it/s, v_num=26]   TRRAINING: Batch 5, loss 8.66895580291748\n",
      "Epoch 0: |          | 6/? [00:05<00:00,  1.20it/s, v_num=26]   TRRAINING: Batch 6, loss 8.998995780944824\n",
      "Epoch 0: |          | 7/? [00:05<00:00,  1.19it/s, v_num=26]   TRRAINING: Batch 7, loss 8.890582084655762\n",
      "Epoch 0: |          | 8/? [00:06<00:00,  1.20it/s, v_num=26]   TRRAINING: Batch 8, loss 8.392278671264648\n",
      "Epoch 0: |          | 9/? [00:07<00:00,  1.20it/s, v_num=26]   TRRAINING: Batch 9, loss 10.367865562438965\n",
      "Epoch 0: |          | 10/? [00:08<00:00,  1.24it/s, v_num=26]   TRRAINING: Batch 10, loss 9.197233200073242\n",
      "Epoch 0: |          | 11/? [00:08<00:00,  1.27it/s, v_num=26]   TRRAINING: Batch 11, loss 8.379603385925293\n",
      "Epoch 0: |          | 12/? [00:09<00:00,  1.28it/s, v_num=26]   TRRAINING: Batch 12, loss 8.649214744567871\n",
      "Epoch 0: |          | 13/? [00:10<00:00,  1.28it/s, v_num=26]   TRRAINING: Batch 13, loss 8.271839141845703\n",
      "Epoch 0: |          | 14/? [00:11<00:00,  1.27it/s, v_num=26]   TRRAINING: Batch 14, loss 8.320290565490723\n",
      "Epoch 0: |          | 15/? [00:11<00:00,  1.26it/s, v_num=26]   TRRAINING: Batch 15, loss 8.004668235778809\n",
      "Epoch 0: |          | 16/? [00:12<00:00,  1.27it/s, v_num=26]   TRRAINING: Batch 16, loss 8.334714889526367\n",
      "Epoch 0: |          | 17/? [00:13<00:00,  1.25it/s, v_num=26]   TRRAINING: Batch 17, loss 8.103826522827148\n",
      "Epoch 0: |          | 18/? [00:14<00:00,  1.25it/s, v_num=26]   TRRAINING: Batch 18, loss 7.877932548522949\n",
      "Epoch 0: |          | 19/? [00:15<00:00,  1.24it/s, v_num=26]   TRRAINING: Batch 19, loss 7.828644752502441\n",
      "Epoch 0: |          | 20/? [00:16<00:00,  1.24it/s, v_num=26]   TRRAINING: Batch 20, loss 7.682406425476074\n",
      "Epoch 0: |          | 21/? [00:17<00:00,  1.23it/s, v_num=26]   TRRAINING: Batch 21, loss 7.342227935791016\n",
      "Epoch 0: |          | 22/? [00:17<00:00,  1.24it/s, v_num=26]ERROR: Input has inproper shape\n",
      "Epoch 0: |          | 23/? [00:17<00:00,  1.30it/s, v_num=26]   VALIDATION: Batch 0, loss 7.465500831604004\n",
      "   VALIDATION: Batch 1, loss 7.236717224121094\n",
      "   VALIDATION: Batch 2, loss 7.776432037353516\n",
      "   VALIDATION: Batch 3, loss 8.007046699523926\n",
      "   VALIDATION: Batch 4, loss 7.579826354980469\n",
      "   VALIDATION: Batch 5, loss 7.941097259521484\n",
      "   VALIDATION: Batch 6, loss 7.581247806549072\n",
      "   VALIDATION: Batch 7, loss 7.47445011138916\n",
      "   VALIDATION: Batch 8, loss 7.362610816955566\n",
      "   VALIDATION: Batch 9, loss 7.342688083648682\n",
      "   VALIDATION: Batch 10, loss 7.418314456939697\n",
      "   VALIDATION: Batch 11, loss 7.620096683502197\n",
      "   VALIDATION: Batch 12, loss 7.209889888763428\n",
      "   VALIDATION: Batch 13, loss 7.600306510925293\n",
      "   VALIDATION: Batch 14, loss 7.509401798248291\n",
      "   VALIDATION: Batch 15, loss 7.550044059753418\n",
      "   VALIDATION: Batch 16, loss 7.872751712799072\n",
      "   VALIDATION: Batch 17, loss 7.6718854904174805\n",
      "ERROR: Input has inproper shape\n",
      "Epoch 1: |          | 0/? [00:00<?, ?it/s, v_num=26]            TRRAINING: Batch 0, loss 8.28051471710205\n",
      "Epoch 1: |          | 1/? [00:01<00:00,  1.00it/s, v_num=26]   TRRAINING: Batch 1, loss 7.0477166175842285\n",
      "Epoch 1: |          | 2/? [00:01<00:00,  1.15it/s, v_num=26]   TRRAINING: Batch 2, loss 7.035760402679443\n",
      "Epoch 1: |          | 3/? [00:02<00:00,  1.20it/s, v_num=26]   TRRAINING: Batch 3, loss 7.07943868637085\n",
      "Epoch 1: |          | 4/? [00:03<00:00,  1.23it/s, v_num=26]   TRRAINING: Batch 4, loss 6.807910919189453\n",
      "Epoch 1: |          | 5/? [00:04<00:00,  1.24it/s, v_num=26]   TRRAINING: Batch 5, loss 7.13535213470459\n",
      "Epoch 1: |          | 6/? [00:04<00:00,  1.22it/s, v_num=26]   TRRAINING: Batch 6, loss 6.9206719398498535\n",
      "Epoch 1: |          | 7/? [00:05<00:00,  1.21it/s, v_num=26]   TRRAINING: Batch 7, loss 7.133737087249756\n",
      "Epoch 1: |          | 8/? [00:06<00:00,  1.23it/s, v_num=26]   TRRAINING: Batch 8, loss 7.582432746887207\n",
      "Epoch 1: |          | 9/? [00:07<00:00,  1.23it/s, v_num=26]   TRRAINING: Batch 9, loss 6.899658203125\n",
      "Epoch 1: |          | 10/? [00:07<00:00,  1.27it/s, v_num=26]   TRRAINING: Batch 10, loss 6.649346828460693\n",
      "Epoch 1: |          | 11/? [00:08<00:00,  1.29it/s, v_num=26]   TRRAINING: Batch 11, loss 6.4778151512146\n",
      "Epoch 1: |          | 12/? [00:09<00:00,  1.30it/s, v_num=26]   TRRAINING: Batch 12, loss 7.952561378479004\n",
      "Epoch 1: |          | 13/? [00:09<00:00,  1.30it/s, v_num=26]   TRRAINING: Batch 13, loss 6.948903560638428\n",
      "Epoch 1: |          | 14/? [00:10<00:00,  1.29it/s, v_num=26]   TRRAINING: Batch 14, loss 7.27277135848999\n",
      "Epoch 1: |          | 15/? [00:11<00:00,  1.28it/s, v_num=26]   TRRAINING: Batch 15, loss 7.069249153137207\n",
      "Epoch 1: |          | 16/? [00:12<00:00,  1.28it/s, v_num=26]   TRRAINING: Batch 16, loss 7.533992767333984\n",
      "Epoch 1: |          | 17/? [00:13<00:00,  1.27it/s, v_num=26]   TRRAINING: Batch 17, loss 7.3287458419799805\n",
      "Epoch 1: |          | 18/? [00:14<00:00,  1.27it/s, v_num=26]   TRRAINING: Batch 18, loss 7.128932952880859\n",
      "Epoch 1: |          | 19/? [00:15<00:00,  1.26it/s, v_num=26]   TRRAINING: Batch 19, loss 6.9806647300720215\n",
      "Epoch 1: |          | 20/? [00:15<00:00,  1.25it/s, v_num=26]   TRRAINING: Batch 20, loss 6.844239711761475\n",
      "Epoch 1: |          | 21/? [00:16<00:00,  1.24it/s, v_num=26]   TRRAINING: Batch 21, loss 6.624578952789307\n",
      "Epoch 1: |          | 22/? [00:17<00:00,  1.26it/s, v_num=26]ERROR: Input has inproper shape\n",
      "Epoch 1: |          | 23/? [00:17<00:00,  1.32it/s, v_num=26]   VALIDATION: Batch 0, loss 7.2679266929626465\n",
      "   VALIDATION: Batch 1, loss 7.029613494873047\n",
      "   VALIDATION: Batch 2, loss 7.48767614364624\n",
      "   VALIDATION: Batch 3, loss 7.7573957443237305\n",
      "   VALIDATION: Batch 4, loss 7.347411155700684\n",
      "   VALIDATION: Batch 5, loss 7.730257511138916\n",
      "   VALIDATION: Batch 6, loss 7.273926734924316\n",
      "   VALIDATION: Batch 7, loss 7.099411964416504\n",
      "   VALIDATION: Batch 8, loss 7.009512424468994\n",
      "   VALIDATION: Batch 9, loss 6.975817680358887\n",
      "   VALIDATION: Batch 10, loss 7.045172691345215\n",
      "   VALIDATION: Batch 11, loss 7.353417873382568\n",
      "   VALIDATION: Batch 12, loss 6.836125373840332\n",
      "   VALIDATION: Batch 13, loss 7.311021327972412\n",
      "   VALIDATION: Batch 14, loss 7.196858882904053\n",
      "   VALIDATION: Batch 15, loss 7.217005729675293\n",
      "   VALIDATION: Batch 16, loss 7.639530181884766\n",
      "   VALIDATION: Batch 17, loss 7.379441738128662\n",
      "ERROR: Input has inproper shape\n",
      "Epoch 2: |          | 0/? [00:00<?, ?it/s, v_num=26]            TRRAINING: Batch 0, loss 7.3217668533325195\n",
      "Epoch 2: |          | 1/? [00:00<00:00,  1.00it/s, v_num=26]   TRRAINING: Batch 1, loss 6.563619136810303\n",
      "Epoch 2: |          | 2/? [00:01<00:00,  1.16it/s, v_num=26]   TRRAINING: Batch 2, loss 6.562453269958496\n",
      "Epoch 2: |          | 3/? [00:02<00:00,  1.21it/s, v_num=26]   TRRAINING: Batch 3, loss 6.643287658691406\n",
      "Epoch 2: |          | 4/? [00:03<00:00,  1.23it/s, v_num=26]   TRRAINING: Batch 4, loss 6.373717308044434\n",
      "Epoch 2: |          | 5/? [00:04<00:00,  1.25it/s, v_num=26]   TRRAINING: Batch 5, loss 6.7509870529174805\n",
      "Epoch 2: |          | 6/? [00:04<00:00,  1.24it/s, v_num=26]   TRRAINING: Batch 6, loss 6.475716590881348\n",
      "Epoch 2: |          | 7/? [00:05<00:00,  1.23it/s, v_num=26]   TRRAINING: Batch 7, loss 6.717794895172119\n",
      "Epoch 2: |          | 8/? [00:06<00:00,  1.24it/s, v_num=26]   TRRAINING: Batch 8, loss 6.895267486572266\n",
      "Epoch 2: |          | 9/? [00:07<00:00,  1.24it/s, v_num=26]   TRRAINING: Batch 9, loss 6.044153690338135\n",
      "Epoch 2: |          | 10/? [00:07<00:00,  1.28it/s, v_num=26]   TRRAINING: Batch 10, loss 5.3112616539001465\n",
      "Epoch 2: |          | 11/? [00:08<00:00,  1.30it/s, v_num=26]   TRRAINING: Batch 11, loss 5.453342437744141\n",
      "Epoch 2: |          | 12/? [00:09<00:00,  1.31it/s, v_num=26]   TRRAINING: Batch 12, loss 6.6415910720825195\n",
      "Epoch 2: |          | 13/? [00:09<00:00,  1.32it/s, v_num=26]   TRRAINING: Batch 13, loss 6.532057285308838\n",
      "Epoch 2: |          | 14/? [00:10<00:00,  1.30it/s, v_num=26]   TRRAINING: Batch 14, loss 6.813789367675781\n",
      "Epoch 2: |          | 15/? [00:11<00:00,  1.29it/s, v_num=26]   TRRAINING: Batch 15, loss 6.383862495422363\n",
      "Epoch 2: |          | 16/? [00:12<00:00,  1.29it/s, v_num=26]   TRRAINING: Batch 16, loss 6.842431545257568\n",
      "Epoch 2: |          | 17/? [00:13<00:00,  1.28it/s, v_num=26]   TRRAINING: Batch 17, loss 6.879154205322266\n",
      "Epoch 2: |          | 18/? [00:14<00:00,  1.28it/s, v_num=26]   TRRAINING: Batch 18, loss 6.664081573486328\n",
      "Epoch 2: |          | 19/? [00:15<00:00,  1.27it/s, v_num=26]   TRRAINING: Batch 19, loss 6.519026279449463\n",
      "Epoch 2: |          | 20/? [00:15<00:00,  1.26it/s, v_num=26]   TRRAINING: Batch 20, loss 6.540022373199463\n",
      "Epoch 2: |          | 21/? [00:16<00:00,  1.25it/s, v_num=26]   TRRAINING: Batch 21, loss 6.282339096069336\n",
      "Epoch 2: |          | 22/? [00:17<00:00,  1.27it/s, v_num=26]ERROR: Input has inproper shape\n",
      "Epoch 2: |          | 23/? [00:17<00:00,  1.32it/s, v_num=26]   VALIDATION: Batch 0, loss 7.055750846862793\n",
      "   VALIDATION: Batch 1, loss 6.85897970199585\n",
      "   VALIDATION: Batch 2, loss 7.306919097900391\n",
      "   VALIDATION: Batch 3, loss 7.654836177825928\n",
      "   VALIDATION: Batch 4, loss 7.111634254455566\n",
      "   VALIDATION: Batch 5, loss 7.549591064453125\n",
      "   VALIDATION: Batch 6, loss 7.074698448181152\n",
      "   VALIDATION: Batch 7, loss 6.90689754486084\n",
      "   VALIDATION: Batch 8, loss 6.801975250244141\n",
      "   VALIDATION: Batch 9, loss 6.7934722900390625\n",
      "   VALIDATION: Batch 10, loss 6.889232635498047\n",
      "   VALIDATION: Batch 11, loss 7.226459503173828\n",
      "   VALIDATION: Batch 12, loss 6.6323699951171875\n",
      "   VALIDATION: Batch 13, loss 7.112815856933594\n",
      "   VALIDATION: Batch 14, loss 7.0185136795043945\n",
      "   VALIDATION: Batch 15, loss 7.04962158203125\n",
      "   VALIDATION: Batch 16, loss 7.447549343109131\n",
      "   VALIDATION: Batch 17, loss 7.213606834411621\n",
      "ERROR: Input has inproper shape\n",
      "Epoch 3: |          | 0/? [00:00<?, ?it/s, v_num=26]            TRRAINING: Batch 0, loss 6.389474868774414\n",
      "Epoch 3: |          | 1/? [00:01<00:00,  0.98it/s, v_num=26]   TRRAINING: Batch 1, loss 6.204166412353516\n",
      "Epoch 3: |          | 2/? [00:01<00:00,  1.13it/s, v_num=26]   TRRAINING: Batch 2, loss 6.159658432006836\n",
      "Epoch 3: |          | 3/? [00:02<00:00,  1.18it/s, v_num=26]   TRRAINING: Batch 3, loss 6.278769493103027\n",
      "Epoch 3: |          | 4/? [00:03<00:00,  1.20it/s, v_num=26]   TRRAINING: Batch 4, loss 6.036111354827881\n",
      "Epoch 3: |          | 5/? [00:04<00:00,  1.22it/s, v_num=26]   TRRAINING: Batch 5, loss 6.460322380065918\n",
      "Epoch 3: |          | 6/? [00:04<00:00,  1.21it/s, v_num=26]   TRRAINING: Batch 6, loss 6.167053699493408\n",
      "Epoch 3: |          | 7/? [00:05<00:00,  1.20it/s, v_num=26]   TRRAINING: Batch 7, loss 6.358770847320557\n",
      "Epoch 3: |          | 8/? [00:06<00:00,  1.22it/s, v_num=26]   TRRAINING: Batch 8, loss 6.383331298828125\n",
      "Epoch 3: |          | 9/? [00:07<00:00,  1.22it/s, v_num=26]   TRRAINING: Batch 9, loss 5.305979251861572\n",
      "Epoch 3: |          | 10/? [00:07<00:00,  1.26it/s, v_num=26]   TRRAINING: Batch 10, loss 4.486598968505859\n",
      "Epoch 3: |          | 11/? [00:08<00:00,  1.28it/s, v_num=26]   TRRAINING: Batch 11, loss 4.67341947555542\n",
      "Epoch 3: |          | 12/? [00:09<00:00,  1.29it/s, v_num=26]   TRRAINING: Batch 12, loss 6.315081596374512\n",
      "Epoch 3: |          | 13/? [00:10<00:00,  1.29it/s, v_num=26]   TRRAINING: Batch 13, loss 6.209807395935059\n",
      "Epoch 3: |          | 14/? [00:11<00:00,  1.27it/s, v_num=26]   TRRAINING: Batch 14, loss 6.351751327514648\n",
      "Epoch 3: |          | 15/? [00:11<00:00,  1.26it/s, v_num=26]   TRRAINING: Batch 15, loss 5.8986735343933105\n",
      "Epoch 3: |          | 16/? [00:12<00:00,  1.27it/s, v_num=26]   TRRAINING: Batch 16, loss 6.402942657470703\n",
      "Epoch 3: |          | 17/? [00:13<00:00,  1.25it/s, v_num=26]   TRRAINING: Batch 17, loss 6.42688512802124\n",
      "Epoch 3: |          | 18/? [00:14<00:00,  1.25it/s, v_num=26]   TRRAINING: Batch 18, loss 6.208579063415527\n",
      "Epoch 3: |          | 19/? [00:15<00:00,  1.24it/s, v_num=26]   TRRAINING: Batch 19, loss 6.166008472442627\n",
      "Epoch 3: |          | 20/? [00:16<00:00,  1.24it/s, v_num=26]   TRRAINING: Batch 20, loss 6.190333366394043\n",
      "Epoch 3: |          | 21/? [00:17<00:00,  1.23it/s, v_num=26]   TRRAINING: Batch 21, loss 5.987107276916504\n",
      "Epoch 3: |          | 22/? [00:17<00:00,  1.25it/s, v_num=26]ERROR: Input has inproper shape\n",
      "Epoch 3: |          | 23/? [00:17<00:00,  1.30it/s, v_num=26]   VALIDATION: Batch 0, loss 7.0613250732421875\n",
      "   VALIDATION: Batch 1, loss 6.841408729553223\n",
      "   VALIDATION: Batch 2, loss 7.300909996032715\n",
      "   VALIDATION: Batch 3, loss 7.686830997467041\n",
      "   VALIDATION: Batch 4, loss 7.054997444152832\n",
      "   VALIDATION: Batch 5, loss 7.638936519622803\n",
      "   VALIDATION: Batch 6, loss 7.067301273345947\n",
      "   VALIDATION: Batch 7, loss 6.816994667053223\n",
      "   VALIDATION: Batch 8, loss 6.821371555328369\n",
      "   VALIDATION: Batch 9, loss 6.79018497467041\n",
      "   VALIDATION: Batch 10, loss 6.902700901031494\n",
      "   VALIDATION: Batch 11, loss 7.271977424621582\n",
      "   VALIDATION: Batch 12, loss 6.6016974449157715\n",
      "   VALIDATION: Batch 13, loss 7.1243720054626465\n",
      "   VALIDATION: Batch 14, loss 7.053769588470459\n",
      "   VALIDATION: Batch 15, loss 7.0967559814453125\n",
      "   VALIDATION: Batch 16, loss 7.508637428283691\n",
      "   VALIDATION: Batch 17, loss 7.246041774749756\n",
      "ERROR: Input has inproper shape\n",
      "Epoch 4: |          | 0/? [00:00<?, ?it/s, v_num=26]            TRRAINING: Batch 0, loss 5.883657932281494\n",
      "Epoch 4: |          | 1/? [00:01<00:00,  0.97it/s, v_num=26]   TRRAINING: Batch 1, loss 5.9156670570373535\n",
      "Epoch 4: |          | 2/? [00:01<00:00,  1.13it/s, v_num=26]   TRRAINING: Batch 2, loss 5.801302909851074\n",
      "Epoch 4: |          | 3/? [00:02<00:00,  1.19it/s, v_num=26]   TRRAINING: Batch 3, loss 5.974084854125977\n",
      "Epoch 4: |          | 4/? [00:03<00:00,  1.21it/s, v_num=26]   TRRAINING: Batch 4, loss 5.742321491241455\n",
      "Epoch 4: |          | 5/? [00:04<00:00,  1.23it/s, v_num=26]   TRRAINING: Batch 5, loss 6.110415458679199\n",
      "Epoch 4: |          | 6/? [00:04<00:00,  1.21it/s, v_num=26]   TRRAINING: Batch 6, loss 5.860136985778809\n",
      "Epoch 4: |          | 7/? [00:05<00:00,  1.21it/s, v_num=26]   TRRAINING: Batch 7, loss 6.032441139221191\n",
      "Epoch 4: |          | 8/? [00:06<00:00,  1.23it/s, v_num=26]   TRRAINING: Batch 8, loss 6.073681354522705\n",
      "Epoch 4: |          | 9/? [00:07<00:00,  1.23it/s, v_num=26]   TRRAINING: Batch 9, loss 4.7292890548706055\n",
      "Epoch 4: |          | 10/? [00:07<00:00,  1.27it/s, v_num=26]   TRRAINING: Batch 10, loss 4.280057907104492\n",
      "Epoch 4: |          | 11/? [00:08<00:00,  1.29it/s, v_num=26]   TRRAINING: Batch 11, loss 4.4189453125\n",
      "Epoch 4: |          | 12/? [00:09<00:00,  1.30it/s, v_num=26]   TRRAINING: Batch 12, loss 5.931446075439453\n",
      "Epoch 4: |          | 13/? [00:09<00:00,  1.30it/s, v_num=26]   TRRAINING: Batch 13, loss 5.893859386444092\n",
      "Epoch 4: |          | 14/? [00:10<00:00,  1.29it/s, v_num=26]   TRRAINING: Batch 14, loss 6.170506954193115\n",
      "Epoch 4: |          | 15/? [00:11<00:00,  1.28it/s, v_num=26]   TRRAINING: Batch 15, loss 5.563003063201904\n",
      "Epoch 4: |          | 16/? [00:12<00:00,  1.28it/s, v_num=26]   TRRAINING: Batch 16, loss 5.996058464050293\n",
      "Epoch 4: |          | 17/? [00:13<00:00,  1.26it/s, v_num=26]   TRRAINING: Batch 17, loss 6.110642433166504\n",
      "Epoch 4: |          | 18/? [00:14<00:00,  1.27it/s, v_num=26]   TRRAINING: Batch 18, loss 5.851583003997803\n",
      "Epoch 4: |          | 19/? [00:15<00:00,  1.26it/s, v_num=26]   TRRAINING: Batch 19, loss 5.893105506896973\n",
      "Epoch 4: |          | 20/? [00:15<00:00,  1.25it/s, v_num=26]   TRRAINING: Batch 20, loss 5.90437650680542\n",
      "Epoch 4: |          | 21/? [00:16<00:00,  1.24it/s, v_num=26]   TRRAINING: Batch 21, loss 5.6552886962890625\n",
      "Epoch 4: |          | 22/? [00:17<00:00,  1.26it/s, v_num=26]ERROR: Input has inproper shape\n",
      "Epoch 4: |          | 23/? [00:17<00:00,  1.31it/s, v_num=26]   VALIDATION: Batch 0, loss 6.913002014160156\n",
      "   VALIDATION: Batch 1, loss 6.723456382751465\n",
      "   VALIDATION: Batch 2, loss 7.1831817626953125\n",
      "   VALIDATION: Batch 3, loss 7.627780914306641\n",
      "   VALIDATION: Batch 4, loss 6.936844825744629\n",
      "   VALIDATION: Batch 5, loss 7.549582481384277\n",
      "   VALIDATION: Batch 6, loss 6.9724440574646\n",
      "   VALIDATION: Batch 7, loss 6.685741424560547\n",
      "   VALIDATION: Batch 8, loss 6.705306053161621\n",
      "   VALIDATION: Batch 9, loss 6.656546115875244\n",
      "   VALIDATION: Batch 10, loss 6.800506591796875\n",
      "   VALIDATION: Batch 11, loss 7.197534084320068\n",
      "   VALIDATION: Batch 12, loss 6.4642333984375\n",
      "   VALIDATION: Batch 13, loss 7.019914150238037\n",
      "   VALIDATION: Batch 14, loss 6.9588799476623535\n",
      "   VALIDATION: Batch 15, loss 6.969046115875244\n",
      "   VALIDATION: Batch 16, loss 7.417233943939209\n",
      "   VALIDATION: Batch 17, loss 7.142411708831787\n",
      "ERROR: Input has inproper shape\n",
      "Epoch 5: |          | 0/? [00:00<?, ?it/s, v_num=26]            TRRAINING: Batch 0, loss 5.661160469055176\n",
      "Epoch 5: |          | 1/? [00:01<00:00,  0.97it/s, v_num=26]   TRRAINING: Batch 1, loss 5.527209281921387\n",
      "Epoch 5: |          | 2/? [00:01<00:00,  1.10it/s, v_num=26]   TRRAINING: Batch 2, loss 5.4865922927856445\n",
      "Epoch 5: |          | 3/? [00:02<00:00,  1.15it/s, v_num=26]   TRRAINING: Batch 3, loss 5.75285530090332\n",
      "Epoch 5: |          | 4/? [00:03<00:00,  1.17it/s, v_num=26]   TRRAINING: Batch 4, loss 5.384124755859375\n",
      "Epoch 5: |          | 5/? [00:04<00:00,  1.19it/s, v_num=26]   TRRAINING: Batch 5, loss 5.843795299530029\n",
      "Epoch 5: |          | 6/? [00:05<00:00,  1.17it/s, v_num=26]   TRRAINING: Batch 6, loss 5.621527194976807\n",
      "Epoch 5: |          | 7/? [00:06<00:00,  1.16it/s, v_num=26]   TRRAINING: Batch 7, loss 5.823035717010498\n",
      "Epoch 5: |          | 8/? [00:06<00:00,  1.18it/s, v_num=26]   TRRAINING: Batch 8, loss 5.752327919006348\n",
      "Epoch 5: |          | 9/? [00:07<00:00,  1.18it/s, v_num=26]   TRRAINING: Batch 9, loss 4.832198619842529\n",
      "Epoch 5: |          | 10/? [00:08<00:00,  1.21it/s, v_num=26]   TRRAINING: Batch 10, loss 4.048718452453613\n",
      "Epoch 5: |          | 11/? [00:08<00:00,  1.22it/s, v_num=26]   TRRAINING: Batch 11, loss 4.052895545959473\n",
      "Epoch 5: |          | 12/? [00:09<00:00,  1.23it/s, v_num=26]   TRRAINING: Batch 12, loss 5.748541831970215\n",
      "Epoch 5: |          | 13/? [00:10<00:00,  1.23it/s, v_num=26]   TRRAINING: Batch 13, loss 5.638365745544434\n",
      "Epoch 5: |          | 14/? [00:11<00:00,  1.21it/s, v_num=26]   TRRAINING: Batch 14, loss 5.857837677001953\n",
      "Epoch 5: |          | 15/? [00:12<00:00,  1.21it/s, v_num=26]   TRRAINING: Batch 15, loss 5.249386787414551\n",
      "Epoch 5: |          | 16/? [00:13<00:00,  1.22it/s, v_num=26]   TRRAINING: Batch 16, loss 5.66775369644165\n",
      "Epoch 5: |          | 17/? [00:14<00:00,  1.20it/s, v_num=26]   TRRAINING: Batch 17, loss 5.8513007164001465\n",
      "Epoch 5: |          | 18/? [00:14<00:00,  1.21it/s, v_num=26]   TRRAINING: Batch 18, loss 5.679144859313965\n",
      "Epoch 5: |          | 19/? [00:15<00:00,  1.20it/s, v_num=26]   TRRAINING: Batch 19, loss 5.60595178604126\n",
      "Epoch 5: |          | 20/? [00:16<00:00,  1.19it/s, v_num=26]   TRRAINING: Batch 20, loss 5.6994476318359375\n",
      "Epoch 5: |          | 21/? [00:17<00:00,  1.19it/s, v_num=26]   TRRAINING: Batch 21, loss 5.408490180969238\n",
      "Epoch 5: |          | 22/? [00:18<00:00,  1.20it/s, v_num=26]ERROR: Input has inproper shape\n",
      "Epoch 5: |          | 23/? [00:18<00:00,  1.26it/s, v_num=26]   VALIDATION: Batch 0, loss 6.913637638092041\n",
      "   VALIDATION: Batch 1, loss 6.77175760269165\n",
      "   VALIDATION: Batch 2, loss 7.173482418060303\n",
      "   VALIDATION: Batch 3, loss 7.6477203369140625\n",
      "   VALIDATION: Batch 4, loss 6.9491167068481445\n",
      "   VALIDATION: Batch 5, loss 7.495718479156494\n",
      "   VALIDATION: Batch 6, loss 6.951573848724365\n",
      "   VALIDATION: Batch 7, loss 6.718574523925781\n",
      "   VALIDATION: Batch 8, loss 6.667479038238525\n",
      "   VALIDATION: Batch 9, loss 6.634016990661621\n",
      "   VALIDATION: Batch 10, loss 6.787131309509277\n",
      "   VALIDATION: Batch 11, loss 7.181548118591309\n",
      "   VALIDATION: Batch 12, loss 6.459176540374756\n",
      "   VALIDATION: Batch 13, loss 7.004416465759277\n",
      "   VALIDATION: Batch 14, loss 6.950168609619141\n",
      "   VALIDATION: Batch 15, loss 6.950597286224365\n",
      "   VALIDATION: Batch 16, loss 7.407168388366699\n",
      "   VALIDATION: Batch 17, loss 7.120123386383057\n",
      "ERROR: Input has inproper shape\n",
      "Epoch 6: |          | 0/? [00:00<?, ?it/s, v_num=26]            TRRAINING: Batch 0, loss 5.142334938049316\n",
      "Epoch 6: |          | 1/? [00:01<00:00,  1.00it/s, v_num=26]   TRRAINING: Batch 1, loss 5.2913923263549805\n",
      "Epoch 6: |          | 2/? [00:01<00:00,  1.15it/s, v_num=26]   TRRAINING: Batch 2, loss 5.316026210784912\n",
      "Epoch 6: |          | 3/? [00:02<00:00,  1.20it/s, v_num=26]   TRRAINING: Batch 3, loss 5.437609672546387\n",
      "Epoch 6: |          | 4/? [00:03<00:00,  1.23it/s, v_num=26]   TRRAINING: Batch 4, loss 5.207396507263184\n",
      "Epoch 6: |          | 5/? [00:04<00:00,  1.24it/s, v_num=26]   TRRAINING: Batch 5, loss 5.578058242797852\n",
      "Epoch 6: |          | 6/? [00:04<00:00,  1.22it/s, v_num=26]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Komputer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "# Define the checkpoint callback to save the model every 1000 batches\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=model_saving_path,  # Directory to save the checkpoints\n",
    "    filename=saving_filename,  # Filename pattern\n",
    "    save_top_k=-1,  # Save all models\n",
    "    save_weights_only=False,  # Save only the weights (or set to False to save the full model)\n",
    "    every_n_train_steps=save_every_n_baches  # Save the model every 1000 batches\n",
    ")\n",
    "#new tensorboard for displaying logs\n",
    "\n",
    "# Define the logger\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"moe_plain_model\") ### CHANGE NAME FOR DIFFERENT RUN (different model)\n",
    "\n",
    "# Initialize the trainer with the checkpoint callback\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=[checkpoint_callback],\n",
    "    max_epochs=epochs, # Set the number of epochs\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "trainer.fit(model = model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    batch_idx   val_loss\n",
      "0           0  10.509090\n",
      "1           1  10.533659\n",
      "2           0   7.635991\n",
      "3           1   7.299952\n",
      "4           2   7.781688\n",
      "5           3   7.924422\n",
      "6           4   7.558314\n",
      "7           5   7.898718\n",
      "8           6   7.490449\n",
      "9           7   7.570178\n",
      "10          8   7.404633\n",
      "11          9   7.353227\n",
      "12         10   7.346442\n",
      "13         11   7.593083\n",
      "14         12   7.275128\n",
      "15         13   7.496394\n",
      "16         14   7.480696\n",
      "17         15   7.463328\n",
      "18         16   7.805147\n",
      "19         17   7.610564\n",
      "    batch_idx  train_loss\n",
      "0           0   10.503899\n",
      "1           1   10.457583\n",
      "2           2   10.151628\n",
      "3           3   10.159952\n",
      "4           4    9.520422\n",
      "5           5    9.292139\n",
      "6           6    9.466715\n",
      "7           7    8.826136\n",
      "8           8    9.118588\n",
      "9           9    9.344730\n",
      "10         10    9.162207\n",
      "11         11    8.577986\n",
      "12         12    8.826115\n",
      "13         13    8.224370\n",
      "14         14    8.281962\n",
      "15         15    7.891154\n",
      "16         16    8.150372\n",
      "17         17    7.977693\n",
      "18         18    7.802260\n",
      "19         19    7.789946\n",
      "20         20    7.619405\n",
      "21         21    7.431582\n",
      "DataFrame saved to D:/Projekt_NLP/Saved_stuff/logs/vectorized_moe\\logs_train_Normal_moe_model.csv\n",
      "DataFrame saved to D:/Projekt_NLP/Saved_stuff/logs/vectorized_moe\\logs_val_Normal_moe_model.csv\n"
     ]
    }
   ],
   "source": [
    "### Saving logs to csv\n",
    "val_data=model.val_losses_list\n",
    "train_data=model.train_losses_list\n",
    "# Convert list of dictionaries to DataFrame\n",
    "log_val_df = pd.DataFrame(val_data)\n",
    "log_train_df = pd.DataFrame(train_data)\n",
    "\n",
    "print(log_val_df)\n",
    "print(log_train_df)\n",
    "\n",
    "# Directory to save the CSV file\n",
    "save_dir = log_saving_path #'/path/to/your/directory'  # Replace with your desired directory path\n",
    "os.makedirs(save_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "# save_dir = 'D:/Projekt_NLP/Saved_stuff/logs/vectorized_moe'#'/path/to/your/directory'  # Replace with your desired directory path\n",
    "# os.makedirs(save_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "model_name='Normal_moe_model'\n",
    "# Define the filename for your CSV file\n",
    "csv_filename_train = f'logs_train_{model_name}.csv'\n",
    "csv_filename_val = f'logs_val_{model_name}.csv'\n",
    "\n",
    "# Construct the full file path\n",
    "csv_file_path_train = os.path.join(save_dir, csv_filename_train)\n",
    "csv_file_path_val = os.path.join(save_dir, csv_filename_val)\n",
    "\n",
    "# Save DataFrame to CSV file\n",
    "log_train_df.to_csv(csv_file_path_train, index=False)\n",
    "log_val_df.to_csv(csv_file_path_val, index=False)\n",
    "\n",
    "print(f\"DataFrame saved to {csv_file_path_train}\")\n",
    "print(f\"DataFrame saved to {csv_file_path_val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training second MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_small= PretrainedConfig(\n",
    "    num_experts_per_token=4,\n",
    "    hidden_size=256,\n",
    "    num_attention_heads = 4,\n",
    "    num_MH_MOE_heads = 4,\n",
    "    num_experts=8,\n",
    "    batch_size = 20,\n",
    "    seq_len = 512,\n",
    "    capacity_factor = 3,\n",
    "    device = device,\n",
    "    intermediate_size = 512,\n",
    "    forward_layer_class = MH_MoE,\n",
    "    vocab_size = 30522,\n",
    "    n_layers = 12,\n",
    "    no_lori_segments = 32,\n",
    "    py_lightning_loging = False,\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(),\n",
    "    lr = 0.001, #SET TO 0.0002\n",
    "    betas = (0.9, 0.98),\n",
    "    treat_mh_lori_as_regular_lori = True,\n",
    "    load_balancing_coefficient=0.01,\n",
    "    proportions = [0.97, 0.01, 0.01, 0.01] # null, train, validation, test\n",
    ")\n",
    "\n",
    "config = config_small\n",
    "\n",
    "#training hiperparams\n",
    "save_every_n_baches = 500 #how often do you wish to save the model\n",
    "epochs = 10\n",
    "\n",
    "#path to folders where you want to save model checkpoints and val and train logs\n",
    "model_saving_path = 'D:/Projekt_NLP/Saved_stuff/saved_models'\n",
    "log_saving_path = 'D:/Projekt_NLP/Saved_stuff/logs/mh_moe'\n",
    "\n",
    "model_name='MH_MoE_model' #name of the model in saving logs\n",
    "saving_filename = 'MH_MOE_175M-{epoch}-{step}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 23/? [05:55<00:00,  0.06it/s, v_num=25]\n",
      "Estimated Model Size: 101.81 MB, total number of parameters: 106,757,352\n",
      "Estimated Model Size: 42.08 MB, total number of parameters: 44,126,208\n",
      "Estimated Model Size: 2.50 MB, total number of parameters: 2,623,488\n",
      "Total GPU memory: 12.8843776 GB\n",
      "Reserved GPU memory: 5.869928448 GB\n",
      "Allocated GPU memory: 0.833367552 GB\n",
      "Free GPU memory: 5.036560896 GB\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(config_small).to(config_small.device)\n",
    "estimate_model_size(model)\n",
    "estimate_model_size(model.layers)\n",
    "estimate_model_size(model.layers[0].forward_layer)\n",
    "get_gpu_memory()\n",
    "print(isinstance(model, LightningModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type             | Params\n",
      "------------------------------------------------\n",
      "0 | loss_fn    | CrossEntropyLoss | 0     \n",
      "1 | embedding  | Embedding        | 7.8 M \n",
      "2 | layers     | ModuleList       | 11.0 M\n",
      "3 | final_proj | Linear           | 7.8 M \n",
      "------------------------------------------------\n",
      "26.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "26.7 M    Total params\n",
      "106.757   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Komputer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]   VALIDATION: Batch 0, loss 10.576143264770508\n",
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  1.26it/s]   VALIDATION: Batch 1, loss 10.658533096313477\n",
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Komputer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 0/? [00:00<?, ?it/s]    TRRAINING: Batch 0, loss 10.509136199951172\n",
      "Epoch 0: |          | 1/? [00:02<00:00,  0.43it/s, v_num=27]   TRRAINING: Batch 1, loss 10.423609733581543\n",
      "Epoch 0: |          | 2/? [00:04<00:00,  0.48it/s, v_num=27]   TRRAINING: Batch 2, loss 9.882196426391602\n",
      "Epoch 0: |          | 3/? [00:06<00:00,  0.49it/s, v_num=27]   TRRAINING: Batch 3, loss 9.192214965820312\n",
      "Epoch 0: |          | 4/? [00:07<00:00,  0.50it/s, v_num=27]   TRRAINING: Batch 4, loss 9.686577796936035\n",
      "Epoch 0: |          | 5/? [00:09<00:00,  0.51it/s, v_num=27]   TRRAINING: Batch 5, loss 8.671618461608887\n",
      "Epoch 0: |          | 6/? [00:11<00:00,  0.51it/s, v_num=27]   TRRAINING: Batch 6, loss 8.795808792114258\n",
      "Epoch 0: |          | 7/? [00:14<00:00,  0.49it/s, v_num=27]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Komputer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "# Define the checkpoint callback to save the model every 1000 batches\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=model_saving_path,  # Directory to save the checkpoints\n",
    "    filename=saving_filename,  # Filename pattern\n",
    "    save_top_k=-1,  # Save all models\n",
    "    save_weights_only=False,  # Save only the weights (or set to False to save the full model)\n",
    "    every_n_train_steps=save_every_n_baches  # Save the model every 1000 batches\n",
    ")\n",
    "#new tensorboard for displaying logs\n",
    "\n",
    "# Define the logger\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"moe_plain_model\") ### CHANGE NAME FOR DIFFERENT RUN (different model)\n",
    "\n",
    "# Initialize the trainer with the checkpoint callback\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=[checkpoint_callback],\n",
    "    max_epochs=epochs, # Set the number of epochs\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "trainer.fit(model = model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving logs to csv\n",
    "val_data=model.val_losses_list\n",
    "train_data=model.train_losses_list\n",
    "# Convert list of dictionaries to DataFrame\n",
    "log_val_df = pd.DataFrame(val_data)\n",
    "log_train_df = pd.DataFrame(train_data)\n",
    "\n",
    "print(log_val_df)\n",
    "print(log_train_df)\n",
    "\n",
    "# Directory to save the CSV file\n",
    "save_dir = log_saving_path #'/path/to/your/directory'  # Replace with your desired directory path\n",
    "os.makedirs(save_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "# save_dir = 'D:/Projekt_NLP/Saved_stuff/logs/vectorized_moe'#'/path/to/your/directory'  # Replace with your desired directory path\n",
    "# os.makedirs(save_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "model_name='Normal_moe_model'\n",
    "# Define the filename for your CSV file\n",
    "csv_filename_train = f'logs_train_{model_name}.csv'\n",
    "csv_filename_val = f'logs_val_{model_name}.csv'\n",
    "\n",
    "# Construct the full file path\n",
    "csv_file_path_train = os.path.join(save_dir, csv_filename_train)\n",
    "csv_file_path_val = os.path.join(save_dir, csv_filename_val)\n",
    "\n",
    "# Save DataFrame to CSV file\n",
    "log_train_df.to_csv(csv_file_path_train, index=False)\n",
    "log_val_df.to_csv(csv_file_path_val, index=False)\n",
    "\n",
    "print(f\"DataFrame saved to {csv_file_path_train}\")\n",
    "print(f\"DataFrame saved to {csv_file_path_val}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
