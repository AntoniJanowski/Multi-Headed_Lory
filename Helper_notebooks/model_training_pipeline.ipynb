{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "main_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(main_dir)\n",
    "\n",
    "import model_classes\n",
    "from model_classes import *\n",
    "from MH_Lori import *\n",
    "from MH_MoE import *\n",
    "from dataloader import *\n",
    "import dataloader\n",
    "from helper_functions import *\n",
    "import torch\n",
    "from transformers import PretrainedConfig\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import copy\n",
    "#import lightning.pytorch as pl\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import pandas as pd\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_small= PretrainedConfig(\n",
    "    num_experts_per_token=2,\n",
    "    hidden_size=128,\n",
    "    num_attention_heads = 8,\n",
    "    num_MH_MOE_heads = 4,\n",
    "    num_experts=12,\n",
    "    batch_size = 1,\n",
    "    seq_len = 512,\n",
    "    capacity_factor = 3,\n",
    "    device = device,\n",
    "    intermediate_size = 256,\n",
    "    forward_layer_class = VectorizedMoE,\n",
    "    vocab_size = 30522,\n",
    "    n_layers = 8,\n",
    "    no_lori_segments = 32,\n",
    "    py_lightning_loging = False,\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(),\n",
    "    lr = 0.0006, #SET TO 0.0002\n",
    "    betas = (0.9, 0.95),\n",
    "    treat_mh_lori_as_regular_lori = False,\n",
    "    load_balancing_coefficient=0.01,\n",
    "    proportions = [0.997, 0.001, 0.001, 0.001] # null, train, validation, test\n",
    ")\n",
    "\n",
    "config = config_small\n",
    "\n",
    "#training hiperparams\n",
    "save_every_n_baches = 500 #how often do you wish to save the model\n",
    "epochs = 10\n",
    "\n",
    "#path to folders where you want to save model checkpoints and val and train logs\n",
    "model_saving_path = 'D:/Projekt_NLP/Saved_stuff/saved_models'\n",
    "log_saving_path = 'D:/Projekt_NLP/Saved_stuff/logs/vectorized_moe'\n",
    "\n",
    "model_name='Normal_moe_model' #name of the model in saving logs\n",
    "saving_filename = '_dataloader_a-{epoch}-{step}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 513])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of usage:\n",
    "l = give_dataloaders(batch_size = config.batch_size, seq_len = config.seq_len + 1, proportions = config.proportions)\n",
    "train_dataloader = l[\"train_dataloader\"]\n",
    "val_dataloader = l[\"val_dataloader\"]\n",
    "test_dataloader = l[\"test_dataloader\"]\n",
    "sample = next(iter(train_dataloader))\n",
    "# print(sample)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Model Size: 55.94 MB, total number of parameters: 58,660,072\n",
      "Estimated Model Size: 26.02 MB, total number of parameters: 27,283,456\n",
      "Estimated Model Size: 3.00 MB, total number of parameters: 3,145,728\n",
      "Total GPU memory: 12.8843776 GB\n",
      "Reserved GPU memory: 0.637534208 GB\n",
      "Allocated GPU memory: 0.200487936 GB\n",
      "Free GPU memory: 0.437046272 GB\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(config_small).to(config_small.device)\n",
    "estimate_model_size(model)\n",
    "estimate_model_size(model.layers)\n",
    "estimate_model_size(model.layers[0].forward_layer)\n",
    "get_gpu_memory()\n",
    "print(isinstance(model, LightningModule))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute this to make shure all parameters are registerd properly\n",
    "\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Parameter name: {name}, Parameter shape: {param.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Komputer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:653: Checkpoint directory D:\\Projekt_NLP\\Saved_stuff\\saved_models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type             | Params\n",
      "------------------------------------------------\n",
      "0 | loss_fn    | CrossEntropyLoss | 0     \n",
      "1 | embedding  | Embedding        | 3.9 M \n",
      "2 | layers     | ModuleList       | 6.8 M \n",
      "3 | final_proj | Linear           | 3.9 M \n",
      "------------------------------------------------\n",
      "14.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "14.7 M    Total params\n",
      "58.660    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Komputer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VALIDATION: Batch 0, loss 10.468964576721191\n",
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  3.31it/s]   VALIDATION: Batch 1, loss 10.485994338989258\n",
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Komputer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 0/? [00:00<?, ?it/s]    TRRAINING: Batch 0, loss 10.45272445678711\n",
      "Epoch 0: |          | 1/? [00:00<00:00,  9.12it/s, v_num=7]   TRRAINING: Batch 1, loss 10.495039939880371\n",
      "Epoch 0: |          | 2/? [00:00<00:00, 10.21it/s, v_num=7]   TRRAINING: Batch 2, loss 10.525457382202148\n",
      "Epoch 0: |          | 3/? [00:00<00:00,  9.07it/s, v_num=7]   TRRAINING: Batch 3, loss 10.31803035736084\n",
      "Epoch 0: |          | 4/? [00:00<00:00,  9.45it/s, v_num=7]   TRRAINING: Batch 4, loss 10.150997161865234\n",
      "Epoch 0: |          | 5/? [00:00<00:00,  9.71it/s, v_num=7]   TRRAINING: Batch 5, loss 10.278472900390625\n",
      "Epoch 0: |          | 6/? [00:00<00:00, 10.10it/s, v_num=7]   TRRAINING: Batch 6, loss 10.345307350158691\n",
      "Epoch 0: |          | 7/? [00:00<00:00, 10.06it/s, v_num=7]   TRRAINING: Batch 7, loss 10.173484802246094\n",
      "Epoch 0: |          | 8/? [00:00<00:00, 10.17it/s, v_num=7]   TRRAINING: Batch 8, loss 10.126062393188477\n",
      "Epoch 0: |          | 9/? [00:00<00:00,  9.78it/s, v_num=7]   TRRAINING: Batch 9, loss 10.526199340820312\n",
      "Epoch 0: |          | 10/? [00:01<00:00,  9.64it/s, v_num=7]   TRRAINING: Batch 10, loss 9.876724243164062\n",
      "Epoch 0: |          | 11/? [00:01<00:00,  9.70it/s, v_num=7]   TRRAINING: Batch 11, loss 9.717597961425781\n",
      "Epoch 0: |          | 12/? [00:01<00:00,  9.88it/s, v_num=7]   TRRAINING: Batch 12, loss 10.775782585144043\n",
      "Epoch 0: |          | 13/? [00:01<00:00, 10.00it/s, v_num=7]   TRRAINING: Batch 13, loss 9.193672180175781\n",
      "Epoch 0: |          | 14/? [00:01<00:00,  9.97it/s, v_num=7]   TRRAINING: Batch 14, loss 8.6136474609375\n",
      "Epoch 0: |          | 15/? [00:01<00:00,  9.96it/s, v_num=7]   TRRAINING: Batch 15, loss 9.34560775756836\n",
      "Epoch 0: |          | 16/? [00:01<00:00,  9.88it/s, v_num=7]   TRRAINING: Batch 16, loss 9.362573623657227\n",
      "Epoch 0: |          | 17/? [00:01<00:00, 10.00it/s, v_num=7]   TRRAINING: Batch 17, loss 8.645560264587402\n",
      "Epoch 0: |          | 18/? [00:01<00:00, 10.07it/s, v_num=7]   TRRAINING: Batch 18, loss 8.862920761108398\n",
      "Epoch 0: |          | 19/? [00:01<00:00, 10.03it/s, v_num=7]   TRRAINING: Batch 19, loss 8.835393905639648\n",
      "Epoch 0: |          | 20/? [00:01<00:00, 10.05it/s, v_num=7]   VALIDATION: Batch 0, loss 10.671074867248535\n",
      "   VALIDATION: Batch 1, loss 8.824972152709961\n",
      "   VALIDATION: Batch 2, loss 8.998638153076172\n",
      "   VALIDATION: Batch 3, loss 9.080421447753906\n",
      "   VALIDATION: Batch 4, loss 8.709171295166016\n",
      "   VALIDATION: Batch 5, loss 8.609992027282715\n",
      "   VALIDATION: Batch 6, loss 8.878609657287598\n",
      "   VALIDATION: Batch 7, loss 8.987176895141602\n",
      "   VALIDATION: Batch 8, loss 8.617402076721191\n",
      "   VALIDATION: Batch 9, loss 6.528903484344482\n",
      "   VALIDATION: Batch 10, loss 8.535628318786621\n",
      "   VALIDATION: Batch 11, loss 8.84359359741211\n",
      "   VALIDATION: Batch 12, loss 8.694310188293457\n",
      "   VALIDATION: Batch 13, loss 8.69117546081543\n",
      "   VALIDATION: Batch 14, loss 8.708683967590332\n",
      "   VALIDATION: Batch 15, loss 8.878890991210938\n",
      "   VALIDATION: Batch 16, loss 8.727651596069336\n",
      "   VALIDATION: Batch 17, loss 8.65230941772461\n",
      "   VALIDATION: Batch 18, loss 8.708032608032227\n",
      "   VALIDATION: Batch 19, loss 8.010407447814941\n",
      "   VALIDATION: Batch 20, loss 8.551535606384277\n",
      "   VALIDATION: Batch 21, loss 8.23576545715332\n",
      "   VALIDATION: Batch 22, loss 8.514957427978516\n",
      "   VALIDATION: Batch 23, loss 8.477988243103027\n",
      "   VALIDATION: Batch 24, loss 8.617297172546387\n",
      "   VALIDATION: Batch 25, loss 8.713075637817383\n",
      "   VALIDATION: Batch 26, loss 8.701177597045898\n",
      "   VALIDATION: Batch 27, loss 8.949043273925781\n",
      "   VALIDATION: Batch 28, loss 9.184449195861816\n",
      "   VALIDATION: Batch 29, loss 8.614850044250488\n",
      "   VALIDATION: Batch 30, loss 8.543764114379883\n",
      "Epoch 1: |          | 0/? [00:00<?, ?it/s, v_num=7]            TRRAINING: Batch 0, loss 7.78993034362793\n",
      "Epoch 1: |          | 1/? [00:00<00:00,  8.57it/s, v_num=7]   TRRAINING: Batch 1, loss 7.66209602355957\n",
      "Epoch 1: |          | 2/? [00:00<00:00, 10.23it/s, v_num=7]   TRRAINING: Batch 2, loss 8.102753639221191\n",
      "Epoch 1: |          | 3/? [00:00<00:00,  8.98it/s, v_num=7]   TRRAINING: Batch 3, loss 7.413545608520508\n",
      "Epoch 1: |          | 4/? [00:00<00:00,  9.37it/s, v_num=7]   TRRAINING: Batch 4, loss 7.0837907791137695\n",
      "Epoch 1: |          | 5/? [00:00<00:00,  9.57it/s, v_num=7]   TRRAINING: Batch 5, loss 7.499393463134766\n",
      "Epoch 1: |          | 6/? [00:00<00:00,  9.94it/s, v_num=7]   TRRAINING: Batch 6, loss 7.954689025878906\n",
      "Epoch 1: |          | 7/? [00:00<00:00,  9.96it/s, v_num=7]   TRRAINING: Batch 7, loss 7.452988147735596\n",
      "Epoch 1: |          | 8/? [00:00<00:00, 10.10it/s, v_num=7]   TRRAINING: Batch 8, loss 7.642330169677734\n",
      "Epoch 1: |          | 9/? [00:00<00:00,  9.72it/s, v_num=7]   TRRAINING: Batch 9, loss 9.026586532592773\n",
      "Epoch 1: |          | 10/? [00:01<00:00,  9.59it/s, v_num=7]   TRRAINING: Batch 10, loss 7.411375999450684\n",
      "Epoch 1: |          | 11/? [00:01<00:00,  9.64it/s, v_num=7]   TRRAINING: Batch 11, loss 7.4371724128723145\n",
      "Epoch 1: |          | 12/? [00:01<00:00,  9.79it/s, v_num=7]   TRRAINING: Batch 12, loss 4.767910957336426\n",
      "Epoch 1: |          | 13/? [00:01<00:00,  9.92it/s, v_num=7]   TRRAINING: Batch 13, loss 7.164158821105957\n",
      "Epoch 1: |          | 14/? [00:01<00:00,  9.92it/s, v_num=7]   TRRAINING: Batch 14, loss 6.44679069519043\n",
      "Epoch 1: |          | 15/? [00:01<00:00,  9.91it/s, v_num=7]   TRRAINING: Batch 15, loss 7.272672176361084\n",
      "Epoch 1: |          | 16/? [00:01<00:00,  9.84it/s, v_num=7]   TRRAINING: Batch 16, loss 5.084336280822754\n",
      "Epoch 1: |          | 17/? [00:01<00:00,  9.96it/s, v_num=7]   TRRAINING: Batch 17, loss 4.617010116577148\n",
      "Epoch 1: |          | 18/? [00:01<00:00, 10.01it/s, v_num=7]   TRRAINING: Batch 18, loss 6.931145668029785\n",
      "Epoch 1: |          | 19/? [00:01<00:00,  9.94it/s, v_num=7]   TRRAINING: Batch 19, loss 6.926296234130859\n",
      "Epoch 1: |          | 20/? [00:02<00:00,  9.97it/s, v_num=7]   VALIDATION: Batch 0, loss 10.672914505004883\n",
      "   VALIDATION: Batch 1, loss 8.153938293457031\n",
      "   VALIDATION: Batch 2, loss 8.266656875610352\n",
      "   VALIDATION: Batch 3, loss 8.373048782348633\n",
      "   VALIDATION: Batch 4, loss 8.2991304397583\n",
      "   VALIDATION: Batch 5, loss 7.842609405517578\n",
      "   VALIDATION: Batch 6, loss 8.180323600769043\n",
      "   VALIDATION: Batch 7, loss 8.290464401245117\n",
      "   VALIDATION: Batch 8, loss 7.648895263671875\n",
      "   VALIDATION: Batch 9, loss 4.042141914367676\n",
      "   VALIDATION: Batch 10, loss 7.638136863708496\n",
      "   VALIDATION: Batch 11, loss 8.016687393188477\n",
      "   VALIDATION: Batch 12, loss 7.653339385986328\n",
      "   VALIDATION: Batch 13, loss 7.907844543457031\n",
      "   VALIDATION: Batch 14, loss 8.050629615783691\n",
      "   VALIDATION: Batch 15, loss 8.231769561767578\n",
      "   VALIDATION: Batch 16, loss 7.808136463165283\n",
      "   VALIDATION: Batch 17, loss 7.946511268615723\n",
      "   VALIDATION: Batch 18, loss 7.886397361755371\n",
      "   VALIDATION: Batch 19, loss 7.4227447509765625\n",
      "   VALIDATION: Batch 20, loss 7.917474746704102\n",
      "   VALIDATION: Batch 21, loss 7.471011638641357\n",
      "   VALIDATION: Batch 22, loss 7.924971103668213\n",
      "   VALIDATION: Batch 23, loss 7.720950603485107\n",
      "   VALIDATION: Batch 24, loss 7.93153190612793\n",
      "   VALIDATION: Batch 25, loss 8.161252975463867\n",
      "   VALIDATION: Batch 26, loss 7.967249870300293\n",
      "   VALIDATION: Batch 27, loss 8.397676467895508\n",
      "   VALIDATION: Batch 28, loss 8.620819091796875\n",
      "   VALIDATION: Batch 29, loss 7.857634544372559\n",
      "   VALIDATION: Batch 30, loss 7.79775333404541\n",
      "Epoch 2: |          | 0/? [00:00<?, ?it/s, v_num=7]            TRRAINING: Batch 0, loss 6.336352348327637\n",
      "Epoch 2: |          | 1/? [00:00<00:00,  8.50it/s, v_num=7]   TRRAINING: Batch 1, loss 6.1879377365112305\n",
      "Epoch 2: |          | 2/? [00:00<00:00, 10.18it/s, v_num=7]   TRRAINING: Batch 2, loss 6.273802757263184\n",
      "Epoch 2: |          | 3/? [00:00<00:00,  8.98it/s, v_num=7]   TRRAINING: Batch 3, loss 6.205164432525635\n",
      "Epoch 2: |          | 4/? [00:00<00:00,  9.37it/s, v_num=7]   TRRAINING: Batch 4, loss 5.750188827514648\n",
      "Epoch 2: |          | 5/? [00:00<00:00,  9.60it/s, v_num=7]   TRRAINING: Batch 5, loss 6.196914196014404\n",
      "Epoch 2: |          | 6/? [00:00<00:00, 10.03it/s, v_num=7]   TRRAINING: Batch 6, loss 6.631867408752441\n",
      "Epoch 2: |          | 7/? [00:00<00:00, 10.03it/s, v_num=7]   TRRAINING: Batch 7, loss 6.43535041809082\n",
      "Epoch 2: |          | 8/? [00:00<00:00, 10.16it/s, v_num=7]   TRRAINING: Batch 8, loss 6.450991630554199\n",
      "Epoch 2: |          | 9/? [00:00<00:00,  9.78it/s, v_num=7]   TRRAINING: Batch 9, loss 7.641156196594238\n",
      "Epoch 2: |          | 10/? [00:01<00:00,  9.63it/s, v_num=7]   TRRAINING: Batch 10, loss 6.521573543548584\n",
      "Epoch 2: |          | 11/? [00:01<00:00,  9.70it/s, v_num=7]   TRRAINING: Batch 11, loss 6.49862003326416\n",
      "Epoch 2: |          | 12/? [00:01<00:00,  9.88it/s, v_num=7]   TRRAINING: Batch 12, loss 5.213050842285156\n",
      "Epoch 2: |          | 13/? [00:01<00:00, 10.00it/s, v_num=7]   TRRAINING: Batch 13, loss 6.487027168273926\n",
      "Epoch 2: |          | 14/? [00:01<00:00,  9.98it/s, v_num=7]   TRRAINING: Batch 14, loss 5.874361038208008\n",
      "Epoch 2: |          | 15/? [00:01<00:00,  9.97it/s, v_num=7]   TRRAINING: Batch 15, loss 6.511101245880127\n",
      "Epoch 2: |          | 16/? [00:01<00:00,  9.90it/s, v_num=7]   TRRAINING: Batch 16, loss 4.3757476806640625\n",
      "Epoch 2: |          | 17/? [00:01<00:00, 10.03it/s, v_num=7]   TRRAINING: Batch 17, loss 3.7579357624053955\n",
      "Epoch 2: |          | 18/? [00:01<00:00, 10.09it/s, v_num=7]   TRRAINING: Batch 18, loss 6.369311332702637\n",
      "Epoch 2: |          | 19/? [00:01<00:00, 10.08it/s, v_num=7]   TRRAINING: Batch 19, loss 6.36550235748291\n",
      "Epoch 2: |          | 20/? [00:01<00:00, 10.11it/s, v_num=7]   VALIDATION: Batch 0, loss 11.581811904907227\n",
      "   VALIDATION: Batch 1, loss 8.499058723449707\n",
      "   VALIDATION: Batch 2, loss 8.676985740661621\n",
      "   VALIDATION: Batch 3, loss 8.828618049621582\n",
      "   VALIDATION: Batch 4, loss 8.86618709564209\n",
      "   VALIDATION: Batch 5, loss 8.100071907043457\n",
      "   VALIDATION: Batch 6, loss 8.567249298095703\n",
      "   VALIDATION: Batch 7, loss 8.711803436279297\n",
      "   VALIDATION: Batch 8, loss 7.624001502990723\n",
      "   VALIDATION: Batch 9, loss 3.3063266277313232\n",
      "   VALIDATION: Batch 10, loss 7.931121826171875\n",
      "   VALIDATION: Batch 11, loss 8.404755592346191\n",
      "   VALIDATION: Batch 12, loss 8.02889633178711\n",
      "   VALIDATION: Batch 13, loss 8.47064208984375\n",
      "   VALIDATION: Batch 14, loss 8.511856079101562\n",
      "   VALIDATION: Batch 15, loss 8.813867568969727\n",
      "   VALIDATION: Batch 16, loss 8.035815238952637\n",
      "   VALIDATION: Batch 17, loss 8.341259956359863\n",
      "   VALIDATION: Batch 18, loss 8.13951301574707\n",
      "   VALIDATION: Batch 19, loss 7.699522018432617\n",
      "   VALIDATION: Batch 20, loss 8.328697204589844\n",
      "   VALIDATION: Batch 21, loss 7.61473274230957\n",
      "   VALIDATION: Batch 22, loss 8.409839630126953\n",
      "   VALIDATION: Batch 23, loss 8.033620834350586\n",
      "   VALIDATION: Batch 24, loss 8.235355377197266\n",
      "   VALIDATION: Batch 25, loss 8.488397598266602\n",
      "   VALIDATION: Batch 26, loss 7.7637939453125\n",
      "   VALIDATION: Batch 27, loss 8.461540222167969\n",
      "   VALIDATION: Batch 28, loss 9.15546989440918\n",
      "   VALIDATION: Batch 29, loss 8.330475807189941\n",
      "   VALIDATION: Batch 30, loss 8.050731658935547\n",
      "Epoch 3: |          | 0/? [00:00<?, ?it/s, v_num=7]            TRRAINING: Batch 0, loss 6.055438041687012\n",
      "Epoch 3: |          | 1/? [00:00<00:00,  8.53it/s, v_num=7]   TRRAINING: Batch 1, loss 5.621257781982422\n",
      "Epoch 3: |          | 2/? [00:00<00:00, 10.20it/s, v_num=7]   TRRAINING: Batch 2, loss 5.413505554199219\n",
      "Epoch 3: |          | 3/? [00:00<00:00,  8.96it/s, v_num=7]   TRRAINING: Batch 3, loss 5.862889289855957\n",
      "Epoch 3: |          | 4/? [00:00<00:00,  9.38it/s, v_num=7]   TRRAINING: Batch 4, loss 5.1516876220703125\n",
      "Epoch 3: |          | 5/? [00:00<00:00,  9.63it/s, v_num=7]   TRRAINING: Batch 5, loss 5.918779373168945\n",
      "Epoch 3: |          | 6/? [00:00<00:00, 10.03it/s, v_num=7]   TRRAINING: Batch 6, loss 6.263011932373047\n",
      "Epoch 3: |          | 7/? [00:00<00:00,  9.99it/s, v_num=7]   TRRAINING: Batch 7, loss 6.038945198059082\n",
      "Epoch 3: |          | 8/? [00:00<00:00, 10.12it/s, v_num=7]   TRRAINING: Batch 8, loss 6.034690856933594\n",
      "Epoch 3: |          | 9/? [00:00<00:00,  9.72it/s, v_num=7]   TRRAINING: Batch 9, loss 6.944598197937012\n",
      "Epoch 3: |          | 10/? [00:01<00:00,  9.56it/s, v_num=7]   TRRAINING: Batch 10, loss 6.074211120605469\n",
      "Epoch 3: |          | 11/? [00:01<00:00,  9.57it/s, v_num=7]   TRRAINING: Batch 11, loss 6.056101322174072\n",
      "Epoch 3: |          | 12/? [00:01<00:00,  9.71it/s, v_num=7]   TRRAINING: Batch 12, loss 3.590376853942871\n",
      "Epoch 3: |          | 13/? [00:01<00:00,  9.84it/s, v_num=7]   TRRAINING: Batch 13, loss 6.142850875854492\n",
      "Epoch 3: |          | 14/? [00:01<00:00,  9.82it/s, v_num=7]   TRRAINING: Batch 14, loss 5.5369391441345215\n",
      "Epoch 3: |          | 15/? [00:01<00:00,  9.83it/s, v_num=7]   TRRAINING: Batch 15, loss 6.095168113708496\n",
      "Epoch 3: |          | 16/? [00:01<00:00,  9.76it/s, v_num=7]   TRRAINING: Batch 16, loss 3.330563545227051\n",
      "Epoch 3: |          | 17/? [00:01<00:00,  9.89it/s, v_num=7]   TRRAINING: Batch 17, loss 3.296394109725952\n",
      "Epoch 3: |          | 18/? [00:01<00:00,  9.96it/s, v_num=7]   TRRAINING: Batch 18, loss 6.041501045227051\n",
      "Epoch 3: |          | 19/? [00:01<00:00,  9.94it/s, v_num=7]   TRRAINING: Batch 19, loss 5.926095008850098\n",
      "Epoch 3: |          | 20/? [00:02<00:00,  9.97it/s, v_num=7]   VALIDATION: Batch 0, loss 12.244470596313477\n",
      "   VALIDATION: Batch 1, loss 8.621360778808594\n",
      "   VALIDATION: Batch 2, loss 8.86678695678711\n",
      "   VALIDATION: Batch 3, loss 8.974138259887695\n",
      "   VALIDATION: Batch 4, loss 9.035852432250977\n",
      "   VALIDATION: Batch 5, loss 8.166797637939453\n",
      "   VALIDATION: Batch 6, loss 8.670430183410645\n",
      "   VALIDATION: Batch 7, loss 8.792810440063477\n",
      "   VALIDATION: Batch 8, loss 7.703800678253174\n",
      "   VALIDATION: Batch 9, loss 2.6259384155273438\n",
      "   VALIDATION: Batch 10, loss 7.943700790405273\n",
      "   VALIDATION: Batch 11, loss 8.579161643981934\n",
      "   VALIDATION: Batch 12, loss 8.082246780395508\n",
      "   VALIDATION: Batch 13, loss 8.535304069519043\n",
      "   VALIDATION: Batch 14, loss 8.66446304321289\n",
      "   VALIDATION: Batch 15, loss 8.852659225463867\n",
      "   VALIDATION: Batch 16, loss 8.12407112121582\n",
      "   VALIDATION: Batch 17, loss 8.449541091918945\n",
      "   VALIDATION: Batch 18, loss 8.280330657958984\n",
      "   VALIDATION: Batch 19, loss 7.8212409019470215\n",
      "   VALIDATION: Batch 20, loss 8.490283966064453\n",
      "   VALIDATION: Batch 21, loss 7.692446231842041\n",
      "   VALIDATION: Batch 22, loss 8.505134582519531\n",
      "   VALIDATION: Batch 23, loss 8.016886711120605\n",
      "   VALIDATION: Batch 24, loss 8.341872215270996\n",
      "   VALIDATION: Batch 25, loss 8.685443878173828\n",
      "   VALIDATION: Batch 26, loss 8.120609283447266\n",
      "   VALIDATION: Batch 27, loss 8.649694442749023\n",
      "   VALIDATION: Batch 28, loss 9.363194465637207\n",
      "   VALIDATION: Batch 29, loss 8.354132652282715\n",
      "   VALIDATION: Batch 30, loss 8.087966918945312\n",
      "Epoch 4: |          | 0/? [00:00<?, ?it/s, v_num=7]            TRRAINING: Batch 0, loss 5.637045860290527\n",
      "Epoch 4: |          | 1/? [00:00<00:00,  8.72it/s, v_num=7]   TRRAINING: Batch 1, loss 5.132397174835205\n",
      "Epoch 4: |          | 2/? [00:00<00:00, 10.37it/s, v_num=7]   TRRAINING: Batch 2, loss 4.6705217361450195\n",
      "Epoch 4: |          | 3/? [00:00<00:00,  9.08it/s, v_num=7]   TRRAINING: Batch 3, loss 5.501370906829834\n",
      "Epoch 4: |          | 4/? [00:00<00:00,  9.50it/s, v_num=7]   TRRAINING: Batch 4, loss 4.783172607421875\n",
      "Epoch 4: |          | 5/? [00:00<00:00,  9.73it/s, v_num=7]   TRRAINING: Batch 5, loss 5.546511173248291\n",
      "Epoch 4: |          | 6/? [00:00<00:00, 10.14it/s, v_num=7]   TRRAINING: Batch 6, loss 5.928468704223633\n",
      "Epoch 4: |          | 7/? [00:00<00:00, 10.15it/s, v_num=7]   TRRAINING: Batch 7, loss 5.711124420166016\n",
      "Epoch 4: |          | 8/? [00:00<00:00, 10.28it/s, v_num=7]   TRRAINING: Batch 8, loss 5.632316589355469\n",
      "Epoch 4: |          | 9/? [00:00<00:00,  9.89it/s, v_num=7]   TRRAINING: Batch 9, loss 6.063891410827637\n",
      "Epoch 4: |          | 10/? [00:01<00:00,  9.75it/s, v_num=7]   TRRAINING: Batch 10, loss 5.665946006774902\n",
      "Epoch 4: |          | 11/? [00:01<00:00,  9.81it/s, v_num=7]   TRRAINING: Batch 11, loss 5.69112491607666\n",
      "Epoch 4: |          | 12/? [00:01<00:00,  9.98it/s, v_num=7]   TRRAINING: Batch 12, loss 4.273469924926758\n",
      "Epoch 4: |          | 13/? [00:01<00:00, 10.11it/s, v_num=7]   TRRAINING: Batch 13, loss 5.832010269165039\n",
      "Epoch 4: |          | 14/? [00:01<00:00, 10.09it/s, v_num=7]   TRRAINING: Batch 14, loss 5.1375298500061035\n",
      "Epoch 4: |          | 15/? [00:01<00:00, 10.08it/s, v_num=7]   TRRAINING: Batch 15, loss 5.74846887588501\n",
      "Epoch 4: |          | 16/? [00:01<00:00, 10.00it/s, v_num=7]   TRRAINING: Batch 16, loss 3.212153911590576\n",
      "Epoch 4: |          | 17/? [00:01<00:00, 10.14it/s, v_num=7]   TRRAINING: Batch 17, loss 3.2427093982696533\n",
      "Epoch 4: |          | 18/? [00:01<00:00, 10.21it/s, v_num=7]   TRRAINING: Batch 18, loss 5.724949836730957\n",
      "Epoch 4: |          | 19/? [00:01<00:00, 10.18it/s, v_num=7]   TRRAINING: Batch 19, loss 5.620114326477051\n",
      "Epoch 4: |          | 20/? [00:01<00:00, 10.21it/s, v_num=7]   VALIDATION: Batch 0, loss 12.651762008666992\n",
      "   VALIDATION: Batch 1, loss 8.740446090698242\n",
      "   VALIDATION: Batch 2, loss 9.090982437133789\n",
      "   VALIDATION: Batch 3, loss 9.016658782958984\n",
      "   VALIDATION: Batch 4, loss 9.119165420532227\n",
      "   VALIDATION: Batch 5, loss 8.374670028686523\n",
      "   VALIDATION: Batch 6, loss 8.639871597290039\n",
      "   VALIDATION: Batch 7, loss 8.938575744628906\n",
      "   VALIDATION: Batch 8, loss 7.602556228637695\n",
      "   VALIDATION: Batch 9, loss 2.2786552906036377\n",
      "   VALIDATION: Batch 10, loss 7.887232780456543\n",
      "   VALIDATION: Batch 11, loss 8.65713119506836\n",
      "   VALIDATION: Batch 12, loss 8.126842498779297\n",
      "   VALIDATION: Batch 13, loss 8.526203155517578\n",
      "   VALIDATION: Batch 14, loss 8.655786514282227\n",
      "   VALIDATION: Batch 15, loss 8.777671813964844\n",
      "   VALIDATION: Batch 16, loss 8.185049057006836\n",
      "   VALIDATION: Batch 17, loss 8.583334922790527\n",
      "   VALIDATION: Batch 18, loss 8.296037673950195\n",
      "   VALIDATION: Batch 19, loss 7.818199634552002\n",
      "   VALIDATION: Batch 20, loss 8.533184051513672\n",
      "   VALIDATION: Batch 21, loss 7.688199996948242\n",
      "   VALIDATION: Batch 22, loss 8.452802658081055\n",
      "   VALIDATION: Batch 23, loss 8.004781723022461\n",
      "   VALIDATION: Batch 24, loss 8.385693550109863\n",
      "   VALIDATION: Batch 25, loss 8.753301620483398\n",
      "   VALIDATION: Batch 26, loss 7.985963344573975\n",
      "   VALIDATION: Batch 27, loss 9.273279190063477\n",
      "   VALIDATION: Batch 28, loss 9.532852172851562\n",
      "   VALIDATION: Batch 29, loss 8.219717979431152\n",
      "   VALIDATION: Batch 30, loss 8.026174545288086\n",
      "Epoch 5: |          | 0/? [00:00<?, ?it/s, v_num=7]            TRRAINING: Batch 0, loss 5.266873836517334\n",
      "Epoch 5: |          | 1/? [00:00<00:00,  8.72it/s, v_num=7]   TRRAINING: Batch 1, loss 4.65451717376709\n",
      "Epoch 5: |          | 2/? [00:00<00:00, 10.39it/s, v_num=7]   TRRAINING: Batch 2, loss 4.079801559448242\n",
      "Epoch 5: |          | 3/? [00:00<00:00,  9.23it/s, v_num=7]   TRRAINING: Batch 3, loss 5.230075836181641\n",
      "Epoch 5: |          | 4/? [00:00<00:00,  9.64it/s, v_num=7]   TRRAINING: Batch 4, loss 4.419737815856934\n",
      "Epoch 5: |          | 5/? [00:00<00:00,  9.87it/s, v_num=7]   TRRAINING: Batch 5, loss 5.412266731262207\n",
      "Epoch 5: |          | 6/? [00:00<00:00, 10.28it/s, v_num=7]   TRRAINING: Batch 6, loss 5.668375015258789\n",
      "Epoch 5: |          | 7/? [00:00<00:00, 10.26it/s, v_num=7]   TRRAINING: Batch 7, loss 5.382534503936768\n",
      "Epoch 5: |          | 8/? [00:00<00:00, 10.40it/s, v_num=7]   TRRAINING: Batch 8, loss 5.294875144958496\n",
      "Epoch 5: |          | 9/? [00:00<00:00, 10.00it/s, v_num=7]   TRRAINING: Batch 9, loss 5.455110549926758\n",
      "Epoch 5: |          | 10/? [00:01<00:00,  9.83it/s, v_num=7]   TRRAINING: Batch 10, loss 5.3947062492370605\n",
      "Epoch 5: |          | 11/? [00:01<00:00,  9.90it/s, v_num=7]   TRRAINING: Batch 11, loss 5.334842681884766\n",
      "Epoch 5: |          | 12/? [00:01<00:00, 10.07it/s, v_num=7]   TRRAINING: Batch 12, loss 3.0287632942199707\n",
      "Epoch 5: |          | 13/? [00:01<00:00, 10.19it/s, v_num=7]   TRRAINING: Batch 13, loss 5.511937141418457\n",
      "Epoch 5: |          | 14/? [00:01<00:00, 10.16it/s, v_num=7]   TRRAINING: Batch 14, loss 4.874521255493164\n",
      "Epoch 5: |          | 15/? [00:01<00:00, 10.16it/s, v_num=7]   TRRAINING: Batch 15, loss 5.410140514373779\n",
      "Epoch 5: |          | 16/? [00:01<00:00, 10.07it/s, v_num=7]   TRRAINING: Batch 16, loss 2.634737968444824\n",
      "Epoch 5: |          | 17/? [00:01<00:00, 10.20it/s, v_num=7]   TRRAINING: Batch 17, loss 2.839237689971924\n",
      "Epoch 5: |          | 18/? [00:01<00:00, 10.26it/s, v_num=7]   TRRAINING: Batch 18, loss 5.44724178314209\n",
      "Epoch 5: |          | 19/? [00:01<00:00, 10.24it/s, v_num=7]   TRRAINING: Batch 19, loss 5.338451385498047\n",
      "Epoch 5: |          | 20/? [00:01<00:00, 10.26it/s, v_num=7]   VALIDATION: Batch 0, loss 13.11783218383789\n",
      "   VALIDATION: Batch 1, loss 8.806124687194824\n",
      "   VALIDATION: Batch 2, loss 9.091878890991211\n",
      "   VALIDATION: Batch 3, loss 9.16709041595459\n",
      "   VALIDATION: Batch 4, loss 9.3506441116333\n",
      "   VALIDATION: Batch 5, loss 8.328836441040039\n",
      "   VALIDATION: Batch 6, loss 8.819098472595215\n",
      "   VALIDATION: Batch 7, loss 9.011371612548828\n",
      "   VALIDATION: Batch 8, loss 7.76594352722168\n",
      "   VALIDATION: Batch 9, loss 2.280094623565674\n",
      "   VALIDATION: Batch 10, loss 7.980625152587891\n",
      "   VALIDATION: Batch 11, loss 8.7317476272583\n",
      "   VALIDATION: Batch 12, loss 8.202224731445312\n",
      "   VALIDATION: Batch 13, loss 8.786487579345703\n",
      "   VALIDATION: Batch 14, loss 8.922462463378906\n",
      "   VALIDATION: Batch 15, loss 8.999809265136719\n",
      "   VALIDATION: Batch 16, loss 8.121944427490234\n",
      "   VALIDATION: Batch 17, loss 8.542181015014648\n",
      "   VALIDATION: Batch 18, loss 8.399518966674805\n",
      "   VALIDATION: Batch 19, loss 8.082342147827148\n",
      "   VALIDATION: Batch 20, loss 8.639263153076172\n",
      "   VALIDATION: Batch 21, loss 7.76551628112793\n",
      "   VALIDATION: Batch 22, loss 8.752801895141602\n",
      "   VALIDATION: Batch 23, loss 8.165167808532715\n",
      "   VALIDATION: Batch 24, loss 8.511919021606445\n",
      "   VALIDATION: Batch 25, loss 8.937356948852539\n",
      "   VALIDATION: Batch 26, loss 8.041484832763672\n",
      "   VALIDATION: Batch 27, loss 8.886604309082031\n",
      "   VALIDATION: Batch 28, loss 9.462187767028809\n",
      "   VALIDATION: Batch 29, loss 8.56649398803711\n",
      "   VALIDATION: Batch 30, loss 8.218086242675781\n",
      "Epoch 6: |          | 0/? [00:00<?, ?it/s, v_num=7]            TRRAINING: Batch 0, loss 4.947886943817139\n",
      "Epoch 6: |          | 1/? [00:00<00:00,  8.57it/s, v_num=7]   TRRAINING: Batch 1, loss 4.34807014465332\n",
      "Epoch 6: |          | 2/? [00:00<00:00, 10.36it/s, v_num=7]   TRRAINING: Batch 2, loss 3.839132308959961\n",
      "Epoch 6: |          | 3/? [00:00<00:00,  9.15it/s, v_num=7]   TRRAINING: Batch 3, loss 4.8796186447143555\n",
      "Epoch 6: |          | 4/? [00:00<00:00,  9.53it/s, v_num=7]   TRRAINING: Batch 4, loss 4.03505802154541\n",
      "Epoch 6: |          | 5/? [00:00<00:00,  9.77it/s, v_num=7]   TRRAINING: Batch 5, loss 5.046563148498535\n",
      "Epoch 6: |          | 6/? [00:00<00:00, 10.16it/s, v_num=7]   TRRAINING: Batch 6, loss 5.274820804595947\n",
      "Epoch 6: |          | 7/? [00:00<00:00, 10.15it/s, v_num=7]   TRRAINING: Batch 7, loss 5.035473346710205\n",
      "Epoch 6: |          | 8/? [00:00<00:00, 10.28it/s, v_num=7]   TRRAINING: Batch 8, loss 4.826260566711426\n",
      "Epoch 6: |          | 9/? [00:00<00:00,  9.87it/s, v_num=7]   TRRAINING: Batch 9, loss 5.471742153167725\n",
      "Epoch 6: |          | 10/? [00:01<00:00,  9.72it/s, v_num=7]   TRRAINING: Batch 10, loss 5.04133939743042\n",
      "Epoch 6: |          | 11/? [00:01<00:00,  9.78it/s, v_num=7]   TRRAINING: Batch 11, loss 4.890554428100586\n",
      "Epoch 6: |          | 12/? [00:01<00:00,  9.95it/s, v_num=7]   TRRAINING: Batch 12, loss 3.5959808826446533\n",
      "Epoch 6: |          | 13/? [00:01<00:00, 10.07it/s, v_num=7]   TRRAINING: Batch 13, loss 5.1403889656066895\n",
      "Epoch 6: |          | 14/? [00:01<00:00, 10.04it/s, v_num=7]   TRRAINING: Batch 14, loss 4.596446514129639\n",
      "Epoch 6: |          | 15/? [00:01<00:00, 10.03it/s, v_num=7]   TRRAINING: Batch 15, loss 5.015249729156494\n",
      "Epoch 6: |          | 16/? [00:01<00:00,  9.96it/s, v_num=7]   TRRAINING: Batch 16, loss 2.7386248111724854\n",
      "Epoch 6: |          | 17/? [00:01<00:00, 10.09it/s, v_num=7]   TRRAINING: Batch 17, loss 3.0231685638427734\n",
      "Epoch 6: |          | 18/? [00:01<00:00, 10.15it/s, v_num=7]   TRRAINING: Batch 18, loss 5.216278076171875\n",
      "Epoch 6: |          | 19/? [00:01<00:00, 10.14it/s, v_num=7]   TRRAINING: Batch 19, loss 5.458183765411377\n",
      "Epoch 6: |          | 20/? [00:01<00:00, 10.17it/s, v_num=7]   VALIDATION: Batch 0, loss 12.909976959228516\n",
      "   VALIDATION: Batch 1, loss 8.907638549804688\n",
      "   VALIDATION: Batch 2, loss 9.271596908569336\n",
      "   VALIDATION: Batch 3, loss 8.940351486206055\n",
      "   VALIDATION: Batch 4, loss 8.996800422668457\n",
      "   VALIDATION: Batch 5, loss 8.479471206665039\n",
      "   VALIDATION: Batch 6, loss 8.581306457519531\n",
      "   VALIDATION: Batch 7, loss 9.37490463256836\n",
      "   VALIDATION: Batch 8, loss 7.52323579788208\n",
      "   VALIDATION: Batch 9, loss 2.178148031234741\n",
      "   VALIDATION: Batch 10, loss 7.690045356750488\n",
      "   VALIDATION: Batch 11, loss 8.62550163269043\n",
      "   VALIDATION: Batch 12, loss 7.916387557983398\n",
      "   VALIDATION: Batch 13, loss 8.453737258911133\n",
      "   VALIDATION: Batch 14, loss 8.828001976013184\n",
      "   VALIDATION: Batch 15, loss 8.58068561553955\n",
      "   VALIDATION: Batch 16, loss 8.112398147583008\n",
      "   VALIDATION: Batch 17, loss 8.247692108154297\n",
      "   VALIDATION: Batch 18, loss 8.103856086730957\n",
      "   VALIDATION: Batch 19, loss 7.837697982788086\n",
      "   VALIDATION: Batch 20, loss 8.368404388427734\n",
      "   VALIDATION: Batch 21, loss 7.8759918212890625\n",
      "   VALIDATION: Batch 22, loss 8.744674682617188\n",
      "   VALIDATION: Batch 23, loss 8.070140838623047\n",
      "   VALIDATION: Batch 24, loss 8.617236137390137\n",
      "   VALIDATION: Batch 25, loss 8.799211502075195\n",
      "   VALIDATION: Batch 26, loss 8.380454063415527\n",
      "   VALIDATION: Batch 27, loss 9.59898567199707\n",
      "   VALIDATION: Batch 28, loss 9.500024795532227\n",
      "   VALIDATION: Batch 29, loss 8.089191436767578\n",
      "   VALIDATION: Batch 30, loss 8.017402648925781\n",
      "Epoch 7: |          | 0/? [00:00<?, ?it/s, v_num=7]            TRRAINING: Batch 0, loss 4.892568588256836\n",
      "Epoch 7: |          | 1/? [00:00<00:00,  8.42it/s, v_num=7]   TRRAINING: Batch 1, loss 4.12674617767334\n",
      "Epoch 7: |          | 2/? [00:00<00:00, 10.18it/s, v_num=7]   TRRAINING: Batch 2, loss 3.86818265914917\n",
      "Epoch 7: |          | 3/? [00:00<00:00,  9.06it/s, v_num=7]   TRRAINING: Batch 3, loss 4.641345024108887\n",
      "Epoch 7: |          | 4/? [00:00<00:00,  9.37it/s, v_num=7]   TRRAINING: Batch 4, loss 3.717111825942993\n",
      "Epoch 7: |          | 5/? [00:00<00:00,  9.64it/s, v_num=7]   TRRAINING: Batch 5, loss 4.835739612579346\n",
      "Epoch 7: |          | 6/? [00:00<00:00, 10.04it/s, v_num=7]   TRRAINING: Batch 6, loss 4.996030807495117\n",
      "Epoch 7: |          | 7/? [00:00<00:00, 10.07it/s, v_num=7]   TRRAINING: Batch 7, loss 4.70419454574585\n",
      "Epoch 7: |          | 8/? [00:00<00:00, 10.23it/s, v_num=7]   TRRAINING: Batch 8, loss 4.512953758239746\n",
      "Epoch 7: |          | 9/? [00:00<00:00,  9.86it/s, v_num=7]   TRRAINING: Batch 9, loss 4.487424850463867\n",
      "Epoch 7: |          | 10/? [00:01<00:00,  9.72it/s, v_num=7]   TRRAINING: Batch 10, loss 4.75424861907959\n",
      "Epoch 7: |          | 11/? [00:01<00:00,  9.79it/s, v_num=7]   TRRAINING: Batch 11, loss 4.598136901855469\n",
      "Epoch 7: |          | 12/? [00:01<00:00,  9.95it/s, v_num=7]   TRRAINING: Batch 12, loss 2.454071044921875\n",
      "Epoch 7: |          | 13/? [00:01<00:00, 10.09it/s, v_num=7]   TRRAINING: Batch 13, loss 4.774747848510742\n",
      "Epoch 7: |          | 14/? [00:01<00:00, 10.07it/s, v_num=7]   TRRAINING: Batch 14, loss 4.31683874130249\n",
      "Epoch 7: |          | 15/? [00:01<00:00, 10.06it/s, v_num=7]   TRRAINING: Batch 15, loss 4.641456604003906\n",
      "Epoch 7: |          | 16/? [00:01<00:00,  9.99it/s, v_num=7]   TRRAINING: Batch 16, loss 2.3678460121154785\n",
      "Epoch 7: |          | 17/? [00:01<00:00, 10.12it/s, v_num=7]   TRRAINING: Batch 17, loss 2.4897027015686035\n",
      "Epoch 7: |          | 18/? [00:01<00:00, 10.19it/s, v_num=7]   TRRAINING: Batch 18, loss 4.935088157653809\n",
      "Epoch 7: |          | 19/? [00:01<00:00, 10.17it/s, v_num=7]   TRRAINING: Batch 19, loss 4.9762468338012695\n",
      "Epoch 7: |          | 20/? [00:01<00:00, 10.20it/s, v_num=7]   VALIDATION: Batch 0, loss 13.09567642211914\n",
      "   VALIDATION: Batch 1, loss 9.091710090637207\n",
      "   VALIDATION: Batch 2, loss 9.385588645935059\n",
      "   VALIDATION: Batch 3, loss 9.350030899047852\n",
      "   VALIDATION: Batch 4, loss 9.62877368927002\n",
      "   VALIDATION: Batch 5, loss 8.609116554260254\n",
      "   VALIDATION: Batch 6, loss 8.944456100463867\n",
      "   VALIDATION: Batch 7, loss 9.362298965454102\n",
      "   VALIDATION: Batch 8, loss 7.842678070068359\n",
      "   VALIDATION: Batch 9, loss 2.1153645515441895\n",
      "   VALIDATION: Batch 10, loss 8.130449295043945\n",
      "   VALIDATION: Batch 11, loss 8.9200439453125\n",
      "   VALIDATION: Batch 12, loss 8.377215385437012\n",
      "   VALIDATION: Batch 13, loss 9.055706024169922\n",
      "   VALIDATION: Batch 14, loss 9.20814323425293\n",
      "   VALIDATION: Batch 15, loss 9.21683120727539\n",
      "   VALIDATION: Batch 16, loss 8.264841079711914\n",
      "   VALIDATION: Batch 17, loss 8.690143585205078\n",
      "   VALIDATION: Batch 18, loss 8.54438304901123\n",
      "   VALIDATION: Batch 19, loss 8.329117774963379\n",
      "   VALIDATION: Batch 20, loss 8.785137176513672\n",
      "   VALIDATION: Batch 21, loss 8.005635261535645\n",
      "   VALIDATION: Batch 22, loss 9.04254150390625\n",
      "   VALIDATION: Batch 23, loss 8.4031343460083\n",
      "   VALIDATION: Batch 24, loss 8.806206703186035\n",
      "   VALIDATION: Batch 25, loss 9.223878860473633\n",
      "   VALIDATION: Batch 26, loss 8.332971572875977\n",
      "   VALIDATION: Batch 27, loss 9.14552116394043\n",
      "   VALIDATION: Batch 28, loss 9.752054214477539\n",
      "   VALIDATION: Batch 29, loss 8.720053672790527\n",
      "   VALIDATION: Batch 30, loss 8.518898010253906\n",
      "Epoch 8: |          | 0/? [00:00<?, ?it/s, v_num=7]            TRRAINING: Batch 0, loss 4.557506084442139\n",
      "Epoch 8: |          | 1/? [00:00<00:00,  8.72it/s, v_num=7]   TRRAINING: Batch 1, loss 3.8325653076171875\n",
      "Epoch 8: |          | 2/? [00:00<00:00, 10.39it/s, v_num=7]   TRRAINING: Batch 2, loss 3.057133674621582\n",
      "Epoch 8: |          | 3/? [00:00<00:00,  9.17it/s, v_num=7]   TRRAINING: Batch 3, loss 4.301219940185547\n",
      "Epoch 8: |          | 4/? [00:00<00:00,  9.55it/s, v_num=7]   TRRAINING: Batch 4, loss 3.4093551635742188\n",
      "Epoch 8: |          | 5/? [00:00<00:00,  9.79it/s, v_num=7]   TRRAINING: Batch 5, loss 4.517870903015137\n",
      "Epoch 8: |          | 6/? [00:00<00:00, 10.21it/s, v_num=7]   TRRAINING: Batch 6, loss 4.581369876861572\n",
      "Epoch 8: |          | 7/? [00:00<00:00, 10.20it/s, v_num=7]   TRRAINING: Batch 7, loss 4.411700248718262\n",
      "Epoch 8: |          | 8/? [00:00<00:00, 10.34it/s, v_num=7]   TRRAINING: Batch 8, loss 4.187195301055908\n",
      "Epoch 8: |          | 9/? [00:00<00:00,  9.96it/s, v_num=7]   TRRAINING: Batch 9, loss 4.088759422302246\n",
      "Epoch 8: |          | 10/? [00:01<00:00,  9.81it/s, v_num=7]   TRRAINING: Batch 10, loss 4.425793170928955\n",
      "Epoch 8: |          | 11/? [00:01<00:00,  9.87it/s, v_num=7]   TRRAINING: Batch 11, loss 4.304653167724609\n",
      "Epoch 8: |          | 12/? [00:01<00:00, 10.04it/s, v_num=7]   TRRAINING: Batch 12, loss 2.4396820068359375\n",
      "Epoch 8: |          | 13/? [00:01<00:00, 10.15it/s, v_num=7]   TRRAINING: Batch 13, loss 4.342765808105469\n",
      "Epoch 8: |          | 14/? [00:01<00:00, 10.14it/s, v_num=7]   TRRAINING: Batch 14, loss 3.985292911529541\n",
      "Epoch 8: |          | 15/? [00:01<00:00, 10.07it/s, v_num=7]   TRRAINING: Batch 15, loss 4.352886199951172\n",
      "Epoch 8: |          | 16/? [00:01<00:00,  9.99it/s, v_num=7]   TRRAINING: Batch 16, loss 2.0045695304870605\n",
      "Epoch 8: |          | 17/? [00:01<00:00, 10.12it/s, v_num=7]   TRRAINING: Batch 17, loss 2.2418124675750732\n",
      "Epoch 8: |          | 18/? [00:01<00:00, 10.18it/s, v_num=7]   TRRAINING: Batch 18, loss 4.713040351867676\n",
      "Epoch 8: |          | 19/? [00:01<00:00, 10.17it/s, v_num=7]   TRRAINING: Batch 19, loss 4.750185012817383\n",
      "Epoch 8: |          | 20/? [00:01<00:00, 10.19it/s, v_num=7]   VALIDATION: Batch 0, loss 13.452392578125\n",
      "   VALIDATION: Batch 1, loss 9.507660865783691\n",
      "   VALIDATION: Batch 2, loss 9.776992797851562\n",
      "   VALIDATION: Batch 3, loss 9.709837913513184\n",
      "   VALIDATION: Batch 4, loss 10.042373657226562\n",
      "   VALIDATION: Batch 5, loss 8.985105514526367\n",
      "   VALIDATION: Batch 6, loss 9.256254196166992\n",
      "   VALIDATION: Batch 7, loss 9.812097549438477\n",
      "   VALIDATION: Batch 8, loss 7.944694519042969\n",
      "   VALIDATION: Batch 9, loss 2.04514217376709\n",
      "   VALIDATION: Batch 10, loss 8.390300750732422\n",
      "   VALIDATION: Batch 11, loss 9.245641708374023\n",
      "   VALIDATION: Batch 12, loss 8.573749542236328\n",
      "   VALIDATION: Batch 13, loss 9.357784271240234\n",
      "   VALIDATION: Batch 14, loss 9.614580154418945\n",
      "   VALIDATION: Batch 15, loss 9.583454132080078\n",
      "   VALIDATION: Batch 16, loss 8.415339469909668\n",
      "   VALIDATION: Batch 17, loss 9.008269309997559\n",
      "   VALIDATION: Batch 18, loss 8.780179977416992\n",
      "   VALIDATION: Batch 19, loss 8.599363327026367\n",
      "   VALIDATION: Batch 20, loss 9.108945846557617\n",
      "   VALIDATION: Batch 21, loss 8.293907165527344\n",
      "   VALIDATION: Batch 22, loss 9.441426277160645\n",
      "   VALIDATION: Batch 23, loss 8.696051597595215\n",
      "   VALIDATION: Batch 24, loss 9.09206771850586\n",
      "   VALIDATION: Batch 25, loss 9.567506790161133\n",
      "   VALIDATION: Batch 26, loss 8.53373908996582\n",
      "   VALIDATION: Batch 27, loss 9.679025650024414\n",
      "   VALIDATION: Batch 28, loss 10.163670539855957\n",
      "   VALIDATION: Batch 29, loss 9.02462100982666\n",
      "   VALIDATION: Batch 30, loss 8.788166046142578\n",
      "Epoch 9: |          | 0/? [00:00<?, ?it/s, v_num=7]            TRRAINING: Batch 0, loss 4.3434858322143555\n",
      "Epoch 9: |          | 1/? [00:00<00:00,  8.72it/s, v_num=7]   TRRAINING: Batch 1, loss 3.4804983139038086\n",
      "Epoch 9: |          | 2/? [00:00<00:00, 10.44it/s, v_num=7]   TRRAINING: Batch 2, loss 2.627995729446411\n",
      "Epoch 9: |          | 3/? [00:00<00:00,  9.23it/s, v_num=7]   TRRAINING: Batch 3, loss 4.057476997375488\n",
      "Epoch 9: |          | 4/? [00:00<00:00,  9.46it/s, v_num=7]   TRRAINING: Batch 4, loss 3.1220226287841797\n",
      "Epoch 9: |          | 5/? [00:00<00:00,  9.70it/s, v_num=7]   TRRAINING: Batch 5, loss 4.234210014343262\n",
      "Epoch 9: |          | 6/? [00:00<00:00, 10.11it/s, v_num=7]   TRRAINING: Batch 6, loss 4.289510726928711\n",
      "Epoch 9: |          | 7/? [00:00<00:00, 10.11it/s, v_num=7]   TRRAINING: Batch 7, loss 4.097280025482178\n",
      "Epoch 9: |          | 8/? [00:00<00:00, 10.24it/s, v_num=7]   TRRAINING: Batch 8, loss 3.920801877975464\n",
      "Epoch 9: |          | 9/? [00:00<00:00,  9.87it/s, v_num=7]   TRRAINING: Batch 9, loss 4.007153511047363\n",
      "Epoch 9: |          | 10/? [00:01<00:00,  9.73it/s, v_num=7]   TRRAINING: Batch 10, loss 4.105931282043457\n",
      "Epoch 9: |          | 11/? [00:01<00:00,  9.80it/s, v_num=7]   TRRAINING: Batch 11, loss 4.065288543701172\n",
      "Epoch 9: |          | 12/? [00:01<00:00,  9.97it/s, v_num=7]   TRRAINING: Batch 12, loss 2.344693660736084\n",
      "Epoch 9: |          | 13/? [00:01<00:00, 10.09it/s, v_num=7]   TRRAINING: Batch 13, loss 4.264095783233643\n",
      "Epoch 9: |          | 14/? [00:01<00:00, 10.08it/s, v_num=7]   TRRAINING: Batch 14, loss 3.830082416534424\n",
      "Epoch 9: |          | 15/? [00:01<00:00, 10.07it/s, v_num=7]   TRRAINING: Batch 15, loss 4.002635478973389\n",
      "Epoch 9: |          | 16/? [00:01<00:00,  9.98it/s, v_num=7]   TRRAINING: Batch 16, loss 1.9980701208114624\n",
      "Epoch 9: |          | 17/? [00:01<00:00, 10.12it/s, v_num=7]   TRRAINING: Batch 17, loss 2.2094197273254395\n",
      "Epoch 9: |          | 18/? [00:01<00:00, 10.18it/s, v_num=7]   TRRAINING: Batch 18, loss 4.3200178146362305\n",
      "Epoch 9: |          | 19/? [00:01<00:00, 10.17it/s, v_num=7]   TRRAINING: Batch 19, loss 4.349841117858887\n",
      "Epoch 9: |          | 20/? [00:01<00:00, 10.19it/s, v_num=7]   VALIDATION: Batch 0, loss 13.67199420928955\n",
      "   VALIDATION: Batch 1, loss 9.570295333862305\n",
      "   VALIDATION: Batch 2, loss 9.98094367980957\n",
      "   VALIDATION: Batch 3, loss 9.87859058380127\n",
      "   VALIDATION: Batch 4, loss 10.161155700683594\n",
      "   VALIDATION: Batch 5, loss 9.089644432067871\n",
      "   VALIDATION: Batch 6, loss 9.394956588745117\n",
      "   VALIDATION: Batch 7, loss 9.958863258361816\n",
      "   VALIDATION: Batch 8, loss 7.99778413772583\n",
      "   VALIDATION: Batch 9, loss 2.0543932914733887\n",
      "   VALIDATION: Batch 10, loss 8.47877025604248\n",
      "   VALIDATION: Batch 11, loss 9.425210952758789\n",
      "   VALIDATION: Batch 12, loss 8.80826473236084\n",
      "   VALIDATION: Batch 13, loss 9.495216369628906\n",
      "   VALIDATION: Batch 14, loss 9.658767700195312\n",
      "   VALIDATION: Batch 15, loss 9.679250717163086\n",
      "   VALIDATION: Batch 16, loss 8.541716575622559\n",
      "   VALIDATION: Batch 17, loss 9.13984203338623\n",
      "   VALIDATION: Batch 18, loss 8.89898681640625\n",
      "   VALIDATION: Batch 19, loss 8.71178150177002\n",
      "   VALIDATION: Batch 20, loss 9.335234642028809\n",
      "   VALIDATION: Batch 21, loss 8.356439590454102\n",
      "   VALIDATION: Batch 22, loss 9.53636360168457\n",
      "   VALIDATION: Batch 23, loss 8.800108909606934\n",
      "   VALIDATION: Batch 24, loss 9.219188690185547\n",
      "   VALIDATION: Batch 25, loss 9.713907241821289\n",
      "   VALIDATION: Batch 26, loss 8.645702362060547\n",
      "   VALIDATION: Batch 27, loss 9.591789245605469\n",
      "   VALIDATION: Batch 28, loss 10.349781036376953\n",
      "   VALIDATION: Batch 29, loss 9.070242881774902\n",
      "   VALIDATION: Batch 30, loss 8.84202766418457\n",
      "Epoch 9: |          | 20/? [00:03<00:00,  5.13it/s, v_num=7]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: |          | 20/? [00:03<00:00,  5.13it/s, v_num=7]\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "# Define the checkpoint callback to save the model every 1000 batches\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=model_saving_path,  # Directory to save the checkpoints\n",
    "    filename=saving_filename,  # Filename pattern\n",
    "    save_top_k=-1,  # Save all models\n",
    "    save_weights_only=False,  # Save only the weights (or set to False to save the full model)\n",
    "    every_n_train_steps=save_every_n_baches  # Save the model every 1000 batches\n",
    ")\n",
    "#new tensorboard for displaying logs\n",
    "\n",
    "# Define the logger\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"moe_plain_model\") ### CHANGE NAME FOR DIFFERENT RUN (different model)\n",
    "\n",
    "# Initialize the trainer with the checkpoint callback\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=[checkpoint_callback],\n",
    "    max_epochs=epochs, # Set the number of epochs\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "trainer.fit(model = model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     batch_idx   val_loss\n",
      "0            0  10.468965\n",
      "1            1  10.485994\n",
      "2            0  10.671075\n",
      "3            1   8.824972\n",
      "4            2   8.998638\n",
      "..         ...        ...\n",
      "307         26   8.645702\n",
      "308         27   9.591789\n",
      "309         28  10.349781\n",
      "310         29   9.070243\n",
      "311         30   8.842028\n",
      "\n",
      "[312 rows x 2 columns]\n",
      "     batch_idx  train_loss\n",
      "0            0   10.452724\n",
      "1            1   10.495040\n",
      "2            2   10.525457\n",
      "3            3   10.318030\n",
      "4            4   10.150997\n",
      "..         ...         ...\n",
      "195         15    4.002635\n",
      "196         16    1.998070\n",
      "197         17    2.209420\n",
      "198         18    4.320018\n",
      "199         19    4.349841\n",
      "\n",
      "[200 rows x 2 columns]\n",
      "DataFrame saved to D:/Projekt_NLP/Saved_stuff/logs/vectorized_moe\\logs_train_Normal_moe_model.csv\n",
      "DataFrame saved to D:/Projekt_NLP/Saved_stuff/logs/vectorized_moe\\logs_val_Normal_moe_model.csv\n"
     ]
    }
   ],
   "source": [
    "### Saving logs to csv\n",
    "val_data=model.val_losses_list\n",
    "train_data=model.train_losses_list\n",
    "# Convert list of dictionaries to DataFrame\n",
    "log_val_df = pd.DataFrame(val_data)\n",
    "log_train_df = pd.DataFrame(train_data)\n",
    "\n",
    "print(log_val_df)\n",
    "print(log_train_df)\n",
    "\n",
    "# Directory to save the CSV file\n",
    "save_dir = log_saving_path #'/path/to/your/directory'  # Replace with your desired directory path\n",
    "os.makedirs(save_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "# save_dir = 'D:/Projekt_NLP/Saved_stuff/logs/vectorized_moe'#'/path/to/your/directory'  # Replace with your desired directory path\n",
    "# os.makedirs(save_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "model_name='Normal_moe_model'\n",
    "# Define the filename for your CSV file\n",
    "csv_filename_train = f'logs_train_{model_name}.csv'\n",
    "csv_filename_val = f'logs_val_{model_name}.csv'\n",
    "\n",
    "# Construct the full file path\n",
    "csv_file_path_train = os.path.join(save_dir, csv_filename_train)\n",
    "csv_file_path_val = os.path.join(save_dir, csv_filename_val)\n",
    "\n",
    "# Save DataFrame to CSV file\n",
    "log_train_df.to_csv(csv_file_path_train, index=False)\n",
    "log_val_df.to_csv(csv_file_path_val, index=False)\n",
    "\n",
    "print(f\"DataFrame saved to {csv_file_path_train}\")\n",
    "print(f\"DataFrame saved to {csv_file_path_val}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
